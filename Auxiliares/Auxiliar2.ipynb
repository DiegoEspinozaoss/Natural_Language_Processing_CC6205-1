{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWM5IugWi5ZV"
      },
      "source": [
        "# *Auxiliar 2:* Redes Neuronales\n",
        "\n",
        "\n",
        "## üìö Objetivos de la clase üìö\n",
        "\n",
        "La clase auxiliar de esta semana tendr√° varios objetivos:\n",
        "\n",
        "- Introducir PyTorch, un Framework para trabajar con Deep Learning\n",
        "- Definir y explicar el concepto de Tensor.\n",
        "- Explicar el uso de GPU en Deep Learning.\n",
        "- Explicar el c√°lculo de derivadas con PyTorch.\n",
        "- Construir un una red Feed Forward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLLTxJRSwscP"
      },
      "source": [
        "# **PyTorch**\n",
        "\n",
        "<!-- Tomar en consideracion que los chicos no han visto nada practico en deep learning. No se les explicaron cosas como optimizers, schedulers, etc asi que hay que ser pedagogicos.\n",
        "\n",
        "* Motivacion, trabajo con tensores, dimensionalidad alta, optimizacion en gpu, utilidad de computo por batch (eficiencia, robustez del modelo, etc)\n",
        "\n",
        "\n",
        "* introducir la api, las operaciones basicas, operaciones de creacion, operaciones inplace, cambiar la forma de los tensores, etc\n",
        "\n",
        "* mostrar el uso de la gpu con ejemplos (mostrar nvidia-smi), revisar codigo agnostico al dispositivo -->\n",
        "\n",
        "\n",
        "------------------------------------------------------\n",
        "Ahora vamos a introducir PyTorch, un framework para hacer Deep Learning, y tambi√©n mostrar dos aplicaciones. Esta herramienta va a ser usada de aqu√≠ hasta el final del curso, as√≠ que es importante que tengan un conocimiento base sobre este framework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2EvTlRNbfSV"
      },
      "source": [
        "## **¬øQu√© es PyTorch exactamente?**\n",
        "\n",
        "PyTorch es un framework para hacer Deep Learning. Las caracter√≠sticas principales que ofrece son:\n",
        "\n",
        "- Operaciones b√°sicas con **tensores**.\n",
        "- Usar f√°cilmente y de forma transparente la **GPU**, si es que existe.\n",
        "- Utilidades ya implementadas para acelerar el desarrollo de **redes neuronales**. Capas lineales, capas recurrentes, capas convolucionales, funciones de activaci√≥n, funciones de p√©rdida, etc.\n",
        "- Motor de **diferenciaci√≥n y propagaci√≥n de gradientes autom√°tico**. Se guarda un registro de las operaciones que se realizan sobre un tensor y luego se puede calcular autom√°ticamente la derivada de un tensor de salida con respecto a los par√°metros que estuvieron involucrados es un c√°lculo.\n",
        "\n",
        "<!-- Como les decia, PyTorch es un framework para hacer deep learning. Las caracteristicas principales de un framework de este tipo es que permite trabajar y realizar operaciones basicas con tensores (abajo explicamos que son y por qu√© nos interesan), permite usar facilmente y de forma transparente la GPU, si es que existe (mas delante explicamos por que querriamos hacer esto)  y tambien viene con varias utilidades ya implementadas para acelerar el desarrollo de redes neuronales. Por ejemplo, viene con varios modulos de redes neuronales, como capas lineales (como las que vieron en clases), capas recurrentes, capas convulocionales (estas se ven mas adelante), funciones de activacion, funciones de perdida, etc. Finalmente, y quiza lo mas importante del framework, es que viene con un motor de diferenciacion y propagacion de gradientes automatico, es decir, se guarda un registro de las operaciones que se realizan sobre un tensor y luego se puede calcular automaticamente la derivada de un tensor de salida con respecto a los parametros que estuvieron involucrados en su calculo.\n",
        "\n",
        "-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woZQw3j2bkPw"
      },
      "source": [
        "## **¬øQu√© es un tensor?**\n",
        "\n",
        "Un tensor es una estructura matem√°tica para organizar datos. De toda la vida hemos sabido lo que es un **n√∫mero**. En √°lgebra lineal vimos que podemos organizar (de forma indexada) varios n√∫meros en lo que llamamos **vector**, y luego extendimos esta organizaci√≥n a una estructura bidimensional, una **matriz**, con filas y columnas.\n",
        "\n",
        "Los **tensores** son una forma de generalizar esta idea. Decimos que un numero wacho es un tensor de 0 dimensiones, un **vector** es un tensor de **1 dimensi√≥n** y una **matriz** es un tensor de **2 dimensiones**. Este concepto nos permite generalizar esta organizaci√≥n de los datos sobre dimensiones mayores. Podemos hablar, por ejemplo, de un **cubo** (un tensor de 3 dimensiones), que se podr√≠a interpretar como varias matrices apiladas, o m√°s generalmente un **tensor de N dimensiones** donde N es un n√∫mero cualquiera (entre mas grande N mas dif√≠cil de imaginar :D).\n",
        "\n",
        "Los tensores de dimensiones mayores se los pueden imaginar como listas, donde sus elementos son tensores de dimensiones menores. Esto lo pueden ver en la siguiente fotaza:\n",
        "\n",
        "(source: knoldus)\n",
        "\n",
        "![visualizacion tensor](https://macrosynergy.com/wp-content/uploads/2019/08/Tensor_01.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-CrbVL5bsrm"
      },
      "source": [
        "## **¬øPor qu√© me interesan los tensores?**\n",
        "\n",
        "Cuando uno trabaja en Deep Learning, es muy com√∫n encontrarse con datos de **alta dimensionalidad**.\n",
        "\n",
        "En **NLP** por ejemplo, vimos que es √∫til representar una **palabra** como un **vector** que captura informaci√≥n de la palabra, ya sea de su contexto, de los caracteres que contiene, etc.\n",
        "\n",
        "![imagen.png](data:image/png;base64,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)\n",
        "\n",
        "Tomando esto en cuenta, vemos que una lista de palabras (una frase) la podemos representar como una **matriz**. A estas alturas ya tenemos un **tensor de 2 dimensiones**\n",
        "\n",
        "![imagen.png](data:image/png;base64,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)\n",
        "\n",
        "¬øQu√© pasa si por alguna raz√≥n queremos operar sobre varias frases a la vez? ¬øQu√© pasa si tenemos una lista de frases? Bueno, ahora tenemos un \"cubo\", un tensor de 3 dimensiones, donde la primera dimensiones corresponde a cada frase dentro del conjunto, la segunda a cada palabra dentro de la frase y finalmente la tercera a cada una las posiciones dentro del vector de embeddings.\n",
        "\n",
        "![imagen.png](data:image/png;base64,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)\n",
        "\n",
        "Esto se repite en muchas m√°s √°reas, por ejemplo una imagen RGB es un tensor de 3 dimensiones, un video, donde hay una lista de im√°genes se puede interpretar como un tensor de 4 dimensiones, y as√≠.\n",
        "\n",
        "Analizar **varios elementos a la vez** es una pr√°ctica com√∫n en Deep Learning. Esto hace que el manejo de **tensores** se vuelva importante debido a que normalmente aumentamos en uno el n√∫mero de dimensiones de los ejemplos al hacer esto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQgtuoz9p9W_"
      },
      "source": [
        "## **Mini-Batches y entrenamiento**\n",
        "\n",
        "En clases se vio que la forma en la que se entrenan las redes neuronales es un **proceso iterativo**, donde en primer lugar se realiza una **predicci√≥n que es mala**, **se calcula una funci√≥n de perdida**, **para cada par√°metro se calcula el gradiente de la _loss_ con respecto a este par√°metro** y luego **se desciende en la direcci√≥n de este gradiente para tratar de llevar los par√°metros a los valores que minimizan la funci√≥n de perdida**.\n",
        "\n",
        "Si este proceso iterativo se llevara a cabo de a un ejemplo a la vez, el valor de **la _loss_ ser√≠a muy dependiente del ejemplo concreto que se acaba de observar** y podr√≠a no ser representativo de la _loss_ general. Esto resulta en actualizaciones ruidosas de los par√°metros, porque la _loss_ para el siguiente ejemplo puede ser muy distinta al valor anterior y as√≠ es como los par√°metros pueden oscilar y tener dificultad para converger.\n",
        "\n",
        "Ac√° es donde nos viene a rescatar el concepto de **_mini-batch_**. Un **Mini-Batch** es un **peque√±o subconjunto aleatorio de muestras** de los datos de entrenamiento. Los ejemplos se pasan por la red en **grupos peque√±os** para que cada conjunto produzca una  **_loss_ m√°s representativa**. Esto le agrega robustez al modelo y lo **ayuda a converger**. El tama√±o del _mini-batch_ (cantidad de ejemplos que se pasan a la vez) se vuelve un hiper par√°metro de la red. Los valores √≥ptimos de tama√±o de _mini-batch_ pueden variar mucho, pero los n√∫meros que yo he visto var√≠an entre 8 y 32, aunque para algunas aplicaciones he visto valores del orden de 1000.\n",
        "\n",
        "\n",
        "Pueden leer un poco m√°s [ac√°](https://machinelearningmastery.com/how-to-control-the-speed-and-stability-of-training-neural-networks-with-gradient-descent-batch-size/) o [ac√°](https://ruder.io/optimizing-gradient-descent/), la secci√≥n introductoria lo explica un poco en m√°s detalle, y cita al libro [Deep Learning](https://www.deeplearningbook.org/), que es muy weno :-)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVtK2_G4bBsp"
      },
      "source": [
        "<br>\n",
        "<center>\n",
        "<img src=\"https://ruder.io/content/images/2016/09/contours_evaluation_optimizers.gif\" width=300 height=300 />\n",
        "</center>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqCm5gsibx5s"
      },
      "source": [
        "\n",
        "\n",
        "## **Ejemplos**\n",
        "La API realmente es muy similar a la de Numpy, as√≠ que veremos s√≥lo unos pocos ejemplos. La documentaci√≥n sobre los tensores la pueden ver [ac√°](https://pytorch.org/docs/stable/tensors.html) y la documentacion general de las operaciones sobre tensores que ofrece pytorch esta [ac√°](https://pytorch.org/docs/stable/torch.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTn7dZVwq-SO",
        "outputId": "4ae89f93-ec3b-4eb5-d43c-1f97a87b31ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting portalocker\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-3.1.1\n"
          ]
        }
      ],
      "source": [
        "# Instalamos portalocker para luego acceder a los datasets de Pytorch\n",
        "!pip install portalocker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsaS37KAzZoj",
        "outputId": "82b26282-c1c2-4fbb-a5ba-cf039ffd6920"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting torch\n",
            "  Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch)\n",
            "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.3.0 (from torch)\n",
            "  Downloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch) (75.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (865.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m97.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m119.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.0 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.7.0 which is incompatible.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.7.0 triton-3.3.0\n",
            "Collecting torchtext\n",
            "  Downloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext) (2.32.3)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from torchtext) (2.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (4.13.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->torchtext) (3.3.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch>=2.3.0->torchtext) (75.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (2025.4.26)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.3.0->torchtext) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.3.0->torchtext) (3.0.2)\n",
            "Downloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchtext\n",
            "Successfully installed torchtext-0.18.0\n"
          ]
        }
      ],
      "source": [
        "# Nos aseguramos que pytorch y torchtext esten en la ultima version\n",
        "!pip install torch -U\n",
        "!pip install torchtext -U\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bhqLuYsIYTtt",
        "outputId": "eaaa8fc4-14c0-47dd-fc2f-78423a6754b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Desde una lista de listas\n",
            " tensor([[2, 3, 4],\n",
            "        [4, 5, 6]])\n",
            "\n",
            "Dimensiones del tensor\n",
            " torch.Size([2, 3])\n",
            "\n",
            "Numero de dimensiones del tensor\n",
            " 2\n"
          ]
        }
      ],
      "source": [
        "# Creacion de un tensor a partir de otra estructura\n",
        "a = [[2,3,4], [4,5,6]]\n",
        "t = torch.tensor(a)\n",
        "print(\"Desde una lista de listas\\n\", t)\n",
        "print(\"\\nDimensiones del tensor\\n\", t.size())\n",
        "print(\"\\nNumero de dimensiones del tensor\\n\", t.dim())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tbmxaTNpeeCI",
        "outputId": "f87685c9-3681-4cbc-e7fd-784e890fc2de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor vacio\n",
            " tensor([[[-1.8465e-19,  6.5203e-39,  1.2168e-38],\n",
            "         [-7.2417e-28,  4.8685e-39,  1.1070e-42]],\n",
            "\n",
            "        [[ 0.0000e+00, -7.3861e-19,  6.5203e-39],\n",
            "         [ 1.2168e-38, -7.2419e-28,  4.8685e-39]]])\n"
          ]
        }
      ],
      "source": [
        "# Creacion de un tensor \"vacio\"\n",
        "t = torch.empty(2,2,3)\n",
        "print(\"Tensor vacio\\n\", t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "n4oh5DZJehaF",
        "outputId": "b8f37c48-6866-41cf-ac90-5b60bf61993c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Puros unos\n",
            " tensor([[[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]]])\n"
          ]
        }
      ],
      "source": [
        "# Creacion de tensores con puros 1 o puros ceros\n",
        "t = torch.ones(2,3,4)\n",
        "# t = torch.zeros(2,3,4,5)\n",
        "print(\"Puros unos\\n\", t) # notar la tercera dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2PLHgzdMe2cb",
        "outputId": "a950c830-d19b-4ee9-cdeb-399fe0353224"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribucion uniforme\n",
            " tensor([[0.9918, 0.4996],\n",
            "        [0.7302, 0.8841],\n",
            "        [0.1926, 0.4007]])\n",
            "\n",
            "Distribucion normal\n",
            " tensor([[ 1.6411,  0.4343,  2.9653],\n",
            "        [ 0.0302,  0.9442, -0.8378]])\n"
          ]
        }
      ],
      "source": [
        "# Random sampling\n",
        "t = torch.empty(3, 2).uniform_() # notar operacion in-place\n",
        "print(\"Distribucion uniforme\\n\", t)\n",
        "\n",
        "t = torch.randn(2, 3)\n",
        "print(\"\\nDistribucion normal\\n\", t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "33AQwoOXobdD",
        "outputId": "b3a52a67-9951-4b1c-89b1-1f37f33f6b59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Operaciones con escalares\n",
            " tensor([[6., 6., 6., 6.],\n",
            "        [6., 6., 6., 6.],\n",
            "        [6., 6., 6., 6.]])\n"
          ]
        }
      ],
      "source": [
        "# Operaciones matematicas\n",
        "t = torch.ones(3,4)\n",
        "print(\"Operaciones con escalares\\n\", t + 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NBINbVumph2W",
        "outputId": "955a2ed6-2b39-4331-eb58-03d5a320be09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Operaciones entre tensores\n",
        "t1 = torch.ones(2, 3)\n",
        "t1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "t2fJNHSJisbC",
        "outputId": "bf9a9288-a541-42b2-9e67-31fe8fa6ae48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Operaciones entre tensores\n",
            " tensor([[3., 3., 3.],\n",
            "        [3., 3., 3.]])\n"
          ]
        }
      ],
      "source": [
        "t2 = torch.ones(2, 3) * 2\n",
        "print(\"Operaciones entre tensores\\n\", t1 + t2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G2ouTAQYXxyH",
        "outputId": "29c09011-0d19-470b-cbcd-a76b4442372c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Suma in-place\n",
            " tensor([[2., 2., 2.],\n",
            "        [2., 2., 2.]])\n"
          ]
        }
      ],
      "source": [
        "# Tambien se pueden hacer operaciones in-place, se modifica el mismo tensor\n",
        "t = torch.ones(2,3)\n",
        "t.add_(1)\n",
        "print(\"Suma in-place\\n\", t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "N33ZYc3LYH94",
        "outputId": "ecebbd53-9181-48de-9f5f-8cf5ce75c0f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensiones de partida\n",
            " torch.Size([16])\n",
            "\n",
            "Usamos el metodo .view() y el -1 para que torch infiera dimensiones\n",
            " torch.Size([2, 8])\n",
            "\n",
            "Podemos volver a aplanar el tensor con .flatten()\n",
            " torch.Size([16])\n",
            "\n",
            "Podemos agregar dimensiones sin agregar datos con .unsqueeze()\n",
            " torch.Size([4, 1, 4])\n",
            "\n",
            "Con .squeeze() podemos sacar todas las dimensiones de tama√±o 1\n",
            " torch.Size([4, 4])\n"
          ]
        }
      ],
      "source": [
        "# Hay veces que es util reorganizar los datos de un tensor, o agregar\n",
        "# dimensiones\n",
        "t = torch.arange(16)\n",
        "print(\"Dimensiones de partida\\n\", t.shape)\n",
        "\n",
        "t = t.view(-1, 8)\n",
        "print(\"\\nUsamos el metodo .view() y el -1 para que torch infiera dimensiones\\n\", t.shape)\n",
        "\n",
        "t = t.flatten() # Aqui tambien se podria usar .view(-1)\n",
        "print(\"\\nPodemos volver a aplanar el tensor con .flatten()\\n\", t.shape)\n",
        "\n",
        "t = t.view(-1, 4).unsqueeze(1) # tambien podria ser .view(-1, 1, 4)\n",
        "print(\"\\nPodemos agregar dimensiones sin agregar datos con .unsqueeze()\\n\", t.shape)\n",
        "\n",
        "t = t.squeeze()\n",
        "print(\"\\nCon .squeeze() podemos sacar todas las dimensiones de tama√±o 1\\n\", t.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "B6MMvvLpL3ro",
        "outputId": "16ebec88-fdbe-4325-a663-132162e780f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dim=0: tensor([-5.4360,  2.1242,  0.2690, -0.8965, -2.8480,  3.2426,  1.5706, -0.1483,\n",
            "        -3.0551, -0.1199])\n",
            "dim=1: tensor([-1.0036, -4.1648,  4.8650, -2.1981, -2.7957])\n"
          ]
        }
      ],
      "source": [
        "# Podemos hacer las tipicas sumas\n",
        "t = torch.randn(5, 10)\n",
        "# dim = 0 es suma de filas y 1 de columnas\n",
        "print(f\"dim=0: {t.sum(dim=0)}\")\n",
        "print(f\"dim=1: {t.sum(dim=1)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Aoqanb1yNtTe"
      },
      "outputs": [],
      "source": [
        "# Tal como con numpy podemos hacer funciones\n",
        "def softmax(T, dim):\n",
        "  T = torch.as_tensor(T)\n",
        "  T = T - torch.max(T)\n",
        "  deno = torch.exp(T)\n",
        "  suma = torch.sum(torch.exp(T), dim=dim, keepdim=True)\n",
        "  output = deno/suma\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sGcH3FZqOBOz",
        "outputId": "9bf50509-5178-43f2-9b59-c73f6f622a14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0931, 0.0694, 0.0044, 0.0261, 0.0184, 0.0441, 0.0039, 0.0759, 0.0273,\n",
              "         0.0090, 0.0969, 0.1145, 0.0402, 0.0402, 0.0065, 0.0084, 0.0050, 0.0049,\n",
              "         0.0213, 0.0177, 0.0302, 0.0185, 0.0598, 0.0184, 0.0256, 0.0266, 0.0202,\n",
              "         0.0063, 0.0299, 0.0075, 0.0187, 0.0110],\n",
              "        [0.1400, 0.0316, 0.0130, 0.0217, 0.0736, 0.0040, 0.0056, 0.0113, 0.0734,\n",
              "         0.0052, 0.0369, 0.0253, 0.0385, 0.1236, 0.0571, 0.0017, 0.0163, 0.0103,\n",
              "         0.0111, 0.0050, 0.0039, 0.0126, 0.0291, 0.0074, 0.0742, 0.0138, 0.0443,\n",
              "         0.0115, 0.0583, 0.0251, 0.0050, 0.0095],\n",
              "        [0.0192, 0.0081, 0.0618, 0.0382, 0.0213, 0.0938, 0.0333, 0.0060, 0.0375,\n",
              "         0.0322, 0.0339, 0.0095, 0.0207, 0.0040, 0.0291, 0.0198, 0.0395, 0.0323,\n",
              "         0.0262, 0.0199, 0.0966, 0.0292, 0.0095, 0.0229, 0.0897, 0.0078, 0.0407,\n",
              "         0.0327, 0.0141, 0.0082, 0.0072, 0.0552],\n",
              "        [0.0170, 0.0601, 0.0352, 0.0403, 0.0440, 0.0419, 0.0055, 0.0073, 0.0181,\n",
              "         0.0112, 0.0362, 0.0229, 0.0337, 0.1119, 0.0216, 0.0187, 0.0324, 0.0076,\n",
              "         0.0724, 0.0128, 0.0036, 0.0149, 0.0299, 0.0459, 0.0609, 0.0042, 0.0289,\n",
              "         0.0174, 0.0245, 0.0188, 0.0315, 0.0684],\n",
              "        [0.0435, 0.1029, 0.0139, 0.0080, 0.0155, 0.0601, 0.0084, 0.0193, 0.0013,\n",
              "         0.0269, 0.0523, 0.0632, 0.0078, 0.0182, 0.0133, 0.0189, 0.0181, 0.0097,\n",
              "         0.0088, 0.0279, 0.0042, 0.0097, 0.0108, 0.0131, 0.0092, 0.0088, 0.0208,\n",
              "         0.0161, 0.1137, 0.0197, 0.0074, 0.2285]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t = torch.randn(5, 32)\n",
        "softmax(t, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Noj-NgUarIXt"
      },
      "source": [
        "## **GPUs y Deep Learning**\n",
        "\n",
        "La **GPU** es lo mismo que la **tarjeta de video** de los computadores. Es un chip que esta dise√±ado para manipular gran cantidad de matrices de p√≠xeles, aplicarles transformaciones, y enviarlas a la pantalla para que las podamos ver. Lo interesante de las **GPU** es que est√°n pensadas espec√≠ficamente para paralelizar c√°lculos debido a su aplicaci√≥n en **matrices**.\n",
        "\n",
        "Como referencia un procesador multi-nucleo tiene entre 4 y 16 n√∫cleos actualmente, mientras que una **GPU** puede f√°cilmente superar los 1000 n√∫cleos (aunque son m√°s simples).\n",
        "\n",
        "La mayor√≠a de las operaciones tensoriales se pueden paralelizar, por lo que la GPU se aprovecha de esta propiedad y es capaz de realizar operaciones sobre una matriz completa en **un solo ciclo de reloj** (muy muy r√°pido). Esto puede mejorar el tiempo de computaci√≥n hasta por un factor de 100 en cierto casos.\n",
        "\n",
        "Es por esto que las GPUs se usan tanto en deep learning, porque el **deep learning esta basado en operaciones b√°sicas sobre tensores**, pero en cantidades enormes. Nos estamos aprovechando de a√±os de investigaci√≥n y desarrollo en c√≥mo subir los FPS de tu juego favorito para darle un uso ~~productivo~~ cient√≠fico.\n",
        "\n",
        "Si bien las GPU son la principal componente utilizada para realizar deep learning, el 2018 Google hizo publicas unos procesadores llamaods [TPU](https://cloud.google.com/tpu?hl=es-419), quienes permiten realizar una parelizaci√≥n extrema en las operaciones. A pesar de sus beneficios, actualmente estos dispositivos solo se encuentran disponibles en los nubes de Google (de puro taca√±os..)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QKNjqMt5qFIJ",
        "outputId": "627e8398-61b2-46b4-90f2-c76675413be7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<iframe\n",
              "    width=\"560\"\n",
              "    height=\"315\"\n",
              "    src=\"https://www.youtube.com/embed/WmW6SD-EHVY?si=6JiPSCuU7hioVPy0&t=60\"\n",
              "    frameborder=\"0\"\n",
              "    allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"\n",
              "    allowfullscreen>\n",
              "</iframe>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%html\n",
        "<iframe\n",
        "    width=\"560\"\n",
        "    height=\"315\"\n",
        "    src=\"https://www.youtube.com/embed/WmW6SD-EHVY?si=6JiPSCuU7hioVPy0&t=60\"\n",
        "    frameborder=\"0\"\n",
        "    allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"\n",
        "    allowfullscreen>\n",
        "</iframe>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3in0Nv1fZ9N"
      },
      "source": [
        "\n",
        "## **Usando la GPU en PyTorch**\n",
        "\n",
        "Otra de las gracias de **PyTorch** es que permite **interactuar con la GPU** de forma muy transparente para el usuario. Mover **tensores** desde la CPU (que es donde se crean por default) hacia la GPU se hace en una pura l√≠nea, y adem√°s es muy simple escribir c√≥digo **agn√≥stico** al dispositivo, lo que significa que si el sistema donde se corre el c√≥digo dispone de GPUs estas se ocupan, pero si no, se ocupa la CPU nom√°s.\n",
        "\n",
        "A continuaci√≥n hay unos ejemplos, y pueden leer m√°s al respecto [ac√°](https://pytorch.org/docs/stable/notes/cuda.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "e8EjrIZnypw5",
        "outputId": "242a7c54-fbfa-4414-b054-801ecf6bddff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu May  8 18:12:26 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Primero usemos un comando de shell para obtener informacion de la GPU\n",
        "# Recuerden cambiar el runtime del colab\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VgAok3BJzSWi",
        "outputId": "1772bd1c-d13a-4286-9656-82b3ba1cdace"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Habemus GPU? True\n",
            "Cuantas GPUs me regala Google? 1\n"
          ]
        }
      ],
      "source": [
        "# Verificar si cuda esta disponible en el entorno\n",
        "print(\"Habemus GPU?\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available(): # Usar esto para codigo agnostico\n",
        "    print(\"Cuantas GPUs me regala Google?\", torch.cuda.device_count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "D1cyvw3mzeMP",
        "outputId": "761a3306-d869-497c-a85a-f7bafc5991fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Los tensores se instancian en la cpu por default\n",
            "Pero se pueden mover al dispositivo cuda:0 usando el methodo .cuda()\n",
            "Tambien se pueden llevar a cuda:0 usando el metodo .to()\n"
          ]
        }
      ],
      "source": [
        "# Mover tensores entre gpu y cpu\n",
        "t = torch.empty(3, 4)\n",
        "print(f\"Los tensores se instancian en la {t.device} por default\")\n",
        "\n",
        "t = t.cuda() # .cuda() retorna un nuevo tensor en GPU\n",
        "print(f\"Pero se pueden mover al dispositivo {t.device} usando el methodo .cuda()\")\n",
        "\n",
        "t = torch.empty(3, 4).to(\"cuda\") # Tambien se puede usar con \"cpu\"\n",
        "print(f\"Tambien se pueden llevar a {t.device} usando el metodo .to()\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yeYMoyGFv9zO",
        "outputId": "0ca1316d-cb21-4b13-a8c4-19e4df7b4815"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu May  8 18:12:27 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0             25W /   70W |     104MiB /  15360MiB |      3%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Veamos el uso de la gpu\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdM5r7Zbz-IH"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46jrmdTCxmC1"
      },
      "source": [
        "# **Clasificaci√≥n de Texto**\n",
        "\n",
        "Ahora usaremos redes feed forward para la clasificaci√≥n de texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6O4hGkW2RLtZ"
      },
      "outputs": [],
      "source": [
        "# Nos aseguramos que pytorch y torchtext esten en la ultima version\n",
        "#!pip install torch -U\n",
        "#!pip install torchtext -U\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCYwbzIolQZg"
      },
      "source": [
        "## Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_a7nTyllOUS"
      },
      "source": [
        "Descarguemos el dataset que usaremos en los ejmplos de esta parte de la auxiliar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eiTRFyZBlV_4",
        "outputId": "d71f5460-cd0d-4f70-ad77-d5c8448e67be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-05-08 18:12:27--  http://raw.githubusercontent.com/uchile-nlp/ArgumentMining2017/master/data/complete_data.csv.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://raw.githubusercontent.com/uchile-nlp/ArgumentMining2017/master/data/complete_data.csv.gz [following]\n",
            "--2025-05-08 18:12:27--  https://raw.githubusercontent.com/uchile-nlp/ArgumentMining2017/master/data/complete_data.csv.gz\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9304385 (8.9M) [application/octet-stream]\n",
            "Saving to: ‚Äòcomplete_data.csv.gz‚Äô\n",
            "\n",
            "complete_data.csv.g 100%[===================>]   8.87M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-05-08 18:12:28 (347 MB/s) - ‚Äòcomplete_data.csv.gz‚Äô saved [9304385/9304385]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget raw.githubusercontent.com/uchile-nlp/ArgumentMining2017/master/data/complete_data.csv.gz\n",
        "# !gunzip complete_data.csv.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EvUG4iRIlYHP",
        "outputId": "739c5703-577e-4dbc-e068-207445d2685a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Ejemplo aleatorio:\n",
            " ('el estado de derecho y su mantenci√≥n es un principio fundamental de la democracia por lo tanto es un tema que debe ser tratado profundamente en la nueva constituci√≥n.', 'Estado de Derecho')\n",
            "\n",
            "Ejemplo aleatorio:\n",
            " ('hubo un acuerdo total de los participantes de que la democracia es el valor que permite dar sustento a los otros principios.', 'Democracia')\n",
            "\n",
            "Ejemplo aleatorio:\n",
            " ('valor fundamental, individual y colectivo que permite el desarrollo en conjunto de la sociedad.', 'Inclasificable/No corresponde')\n"
          ]
        }
      ],
      "source": [
        "import gzip\n",
        "import csv\n",
        "with gzip.open('complete_data.csv.gz', 'rt') as f:\n",
        "  data = csv.DictReader(f, strict=True, escapechar=\"\\\\\")\n",
        "\n",
        "  # Para este ejemplo solo voy a trabajar con documentos de la categoria 1, \"Valores\"\n",
        "  dataset = tuple(\n",
        "      # Usemos lowercase para que el vocabulario no quede tan grande\n",
        "      (row[\"argument\"].lower(), row[\"constitutional_concept\"])\n",
        "      for row in data if row[\"topic\"] == \"1\" and row[\"argument\"]\n",
        "  )\n",
        "\n",
        "dataset = dataset[:10000]\n",
        "\n",
        "# Mostremos algunos ejemplos\n",
        "from random import sample\n",
        "for example in sample(dataset, 3):\n",
        "    print(\"\\nEjemplo aleatorio:\\n\", example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvvzxraUlaCY"
      },
      "source": [
        "## Tokenizaci√≥n y splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iOIc2PHhldJ_",
        "outputId": "a893c881-5139-4a90-8065-5c251f31abd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Algunos ejemplos del dataset:\n",
            "('terminar con la corrupci√≥n.', 'Probidad')\n",
            "('principio fundante de la vida en sociedad, es una funci√≥n implicita del estado de derecho. vital para la resoluci√≥n de conflictos y la convivencia.', 'Justicia')\n",
            "('conceptos votados, son los que sacaron la mayor√≠a de votos.', 'Autonom√≠a / Libertad')\n"
          ]
        }
      ],
      "source": [
        "# Ahora con este vocabulario podemos armar un set de train y uno de validacion\n",
        "import torch\n",
        "from torch.utils.data.dataset import random_split\n",
        "train_len = int(len(dataset) * .8)\n",
        "\n",
        "train_split, validation_split = random_split(dataset, [train_len, len(dataset) - train_len])\n",
        "\n",
        "print(\"Algunos ejemplos del dataset:\")\n",
        "for example in sample(list(train_split), 3):\n",
        "    print(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0tMztgoKTilw",
        "outputId": "879c49f2-fbe7-4d06-844a-cab7459e0653"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from collections import namedtuple\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2gKOSmaIS8tY"
      },
      "outputs": [],
      "source": [
        "document = namedtuple(\n",
        "    \"document\", (\"constitutional_concept\", \"argument\")  # avoid python's keyword collision\n",
        ")\n",
        "\n",
        "tokenized_train_set = [document(argument=tuple(word_tokenize(d[0].lower())), constitutional_concept=d[1]) for d in train_split]\n",
        "train_set = pd.DataFrame(data=tokenized_train_set)\n",
        "\n",
        "tokenized_validation_set = [document(argument=tuple(word_tokenize(d[0].lower())), constitutional_concept=d[1]) for d in validation_split]\n",
        "validation_set = pd.DataFrame(data=tokenized_validation_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "k-18KU4zUVNI",
        "outputId": "4bf131ea-d044-4123-e9a2-19e9a1c27609"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"train_set\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"constitutional_concept\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Inclusi\\u00f3n\",\n          \"Otro\",\n          \"Justicia\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"argument\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          [\n            \"necesitamos\",\n            \"garant\\u00edas\",\n            \"b\\u00e1sicas\",\n            \".\"\n          ],\n          [\n            \"considera\",\n            \"que\",\n            \"todas\",\n            \"las\",\n            \"personas\",\n            \"tienen\",\n            \"el\",\n            \"mismo\",\n            \"valor\",\n            \"s\\u00f3lo\",\n            \"por\",\n            \"su\",\n            \"condici\\u00f3n\",\n            \"de\",\n            \"ser\",\n            \"humano\",\n            \",\",\n            \"lo\",\n            \"que\",\n            \"debe\",\n            \"ser\",\n            \"considerado\",\n            \"durante\",\n            \"todas\",\n            \"las\",\n            \"edades\",\n            \"de\",\n            \"su\",\n            \"vida\",\n            \"(\",\n            \"etariedad\",\n            \")\",\n            \".\",\n            \"-considera\",\n            \"la\",\n            \"igualdad\",\n            \"de\",\n            \"oportunidades\",\n            \"y\",\n            \"acceso\",\n            \"a\",\n            \"lo\",\n            \"econ\\u00f3mico\",\n            \",\",\n            \"a\",\n            \"la\",\n            \"cultura\",\n            \",\",\n            \"a\",\n            \"los\",\n            \"espacios\",\n            \"de\",\n            \"poder\",\n            \"pol\\u00edtico\",\n            \",\",\n            \"a\",\n            \"salarios\",\n            \"dignos\",\n            \"y\",\n            \"acortar\",\n            \"las\",\n            \"diferencias\",\n            \"salariales\",\n            \"entre\",\n            \"los\",\n            \"que\",\n            \"ganan\",\n            \"m\\u00e1s\",\n            \"y\",\n            \"los\",\n            \"que\",\n            \"ganan\",\n            \"menos\",\n            \".\",\n            \"-\",\n            \"el\",\n            \"estado\",\n            \"debe\",\n            \"desarrollar\",\n            \"las\",\n            \"instituciones\",\n            \",\",\n            \"leyes\",\n            \"y\",\n            \"mecanismos\",\n            \"que\",\n            \"aseguren\",\n            \"este\",\n            \"principio\",\n            \"transversalmente\"\n          ],\n          [\n            \"el\",\n            \"grupo\",\n            \"lo\",\n            \"considera\",\n            \"como\",\n            \"derechos\",\n            \"y\",\n            \"deberes\",\n            \"para\",\n            \"todos\",\n            \"los\",\n            \"nacidos\",\n            \"y\",\n            \"residentes\",\n            \"en\",\n            \"el\",\n            \"pa\\u00eds\",\n            \",\",\n            \"por\",\n            \"igual\",\n            \".\",\n            \"(\",\n            \"igualad\",\n            \"de\",\n            \"derecho\",\n            \"ante\",\n            \"educaci\\u00f3n\",\n            \",\",\n            \"g\\u00e9nero\",\n            \"y\",\n            \"sexualidad\",\n            \",\",\n            \"salud\",\n            \",\",\n            \"acceso\",\n            \"cargos\",\n            \"p\\u00fablicos\",\n            \",\",\n            \"votaci\\u00f3n\",\n            \",\",\n            \"ante\",\n            \"la\",\n            \"ley\",\n            \",\",\n            \"seguridad\",\n            \",\",\n            \"igualdad\",\n            \"de\",\n            \"remuneraciones\",\n            \",\",\n            \"entre\",\n            \"otros\",\n            \")\"\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-1d9d9043-5306-4d38-9427-4f7a9d364fd9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>constitutional_concept</th>\n",
              "      <th>argument</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2459</th>\n",
              "      <td>Justicia</td>\n",
              "      <td>(una, sociedad, justa, donde, todos, sean, igu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7475</th>\n",
              "      <td>Inclusi√≥n</td>\n",
              "      <td>(considera, que, todas, las, personas, tienen,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1163</th>\n",
              "      <td>Tolerancia</td>\n",
              "      <td>(debemos, entendernos, ,, aceptarnos, ,, verno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5527</th>\n",
              "      <td>Bien Com√∫n / Comunidad</td>\n",
              "      <td>(-, desde, la, comunidad, -, eje, rector, de, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4675</th>\n",
              "      <td>Bien Com√∫n / Comunidad</td>\n",
              "      <td>(necesario, para, humanizar, sociedad, chilena)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>Igualdad</td>\n",
              "      <td>(el, grupo, lo, considera, como, derechos, y, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7910</th>\n",
              "      <td>Otro</td>\n",
              "      <td>(mejorar, la, calidad, de, salud, ,, no, hay, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3214</th>\n",
              "      <td>Justicia</td>\n",
              "      <td>(el, estado, tiene, que, garantizar, una, just...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2710</th>\n",
              "      <td>Estado de Derecho</td>\n",
              "      <td>(necesitamos, garant√≠as, b√°sicas, .)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1375</th>\n",
              "      <td>Paz / Convivencia pac√≠fica</td>\n",
              "      <td>(principio, fundamental, para, desarrollarse, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d9d9043-5306-4d38-9427-4f7a9d364fd9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1d9d9043-5306-4d38-9427-4f7a9d364fd9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1d9d9043-5306-4d38-9427-4f7a9d364fd9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-16e42e76-8572-4b74-bc84-16076f7fade9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-16e42e76-8572-4b74-bc84-16076f7fade9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-16e42e76-8572-4b74-bc84-16076f7fade9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          constitutional_concept  \\\n",
              "2459                    Justicia   \n",
              "7475                   Inclusi√≥n   \n",
              "1163                  Tolerancia   \n",
              "5527      Bien Com√∫n / Comunidad   \n",
              "4675      Bien Com√∫n / Comunidad   \n",
              "56                      Igualdad   \n",
              "7910                        Otro   \n",
              "3214                    Justicia   \n",
              "2710           Estado de Derecho   \n",
              "1375  Paz / Convivencia pac√≠fica   \n",
              "\n",
              "                                               argument  \n",
              "2459  (una, sociedad, justa, donde, todos, sean, igu...  \n",
              "7475  (considera, que, todas, las, personas, tienen,...  \n",
              "1163  (debemos, entendernos, ,, aceptarnos, ,, verno...  \n",
              "5527  (-, desde, la, comunidad, -, eje, rector, de, ...  \n",
              "4675    (necesario, para, humanizar, sociedad, chilena)  \n",
              "56    (el, grupo, lo, considera, como, derechos, y, ...  \n",
              "7910  (mejorar, la, calidad, de, salud, ,, no, hay, ...  \n",
              "3214  (el, estado, tiene, que, garantizar, una, just...  \n",
              "2710               (necesitamos, garant√≠as, b√°sicas, .)  \n",
              "1375  (principio, fundamental, para, desarrollarse, ...  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_set.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3A6HE_8KUi6g",
        "outputId": "6f0a4cc2-0907-41bf-932f-21d1d9d9f801"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"validation_set\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"constitutional_concept\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Democracia\",\n          \"Estado de Derecho\",\n          \"Justicia\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"argument\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          [\n            \"fue\",\n            \"categ\\u00f3rico\",\n            \"esto\",\n            \",\",\n            \"pues\",\n            \"somos\",\n            \"una\",\n            \"republica\",\n            \"laica\",\n            \"y\",\n            \"no\",\n            \"confesional\",\n            \".\"\n          ],\n          [\n            \"porque\",\n            \"es\",\n            \"el\",\n            \"pilar\",\n            \"fundamental\",\n            \"de\",\n            \"toda\",\n            \"sociedad\",\n            \"y\",\n            \"porque\",\n            \"implica\",\n            \"la\",\n            \"participaci\\u00f3n\",\n            \"de\",\n            \"todos\",\n            \"los\",\n            \"ciudadanos\",\n            \"en\",\n            \"las\",\n            \"decisiones\",\n            \".\"\n          ],\n          [\n            \"tiene\",\n            \"que\",\n            \"ver\",\n            \"con\",\n            \"la\",\n            \"idea\",\n            \"de\",\n            \"sociedad\",\n            \"y\",\n            \"modelo\",\n            \"de\",\n            \"justicia\",\n            \"que\",\n            \"se\",\n            \"tiene\",\n            \".\",\n            \"se\",\n            \"plantea\",\n            \"el\",\n            \"modelo\",\n            \"distributivo\",\n            \",\",\n            \"el\",\n            \"que\",\n            \"recibe\",\n            \"m\\u00e1s\",\n            \"aporta\",\n            \"m\\u00e1s\",\n            \".\",\n            \"generar\",\n            \"un\",\n            \"derecho\",\n            \".\"\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-30d58bb5-20f3-4fef-89dc-eaffcf6449b9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>constitutional_concept</th>\n",
              "      <th>argument</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1552</th>\n",
              "      <td>Justicia</td>\n",
              "      <td>(tiene, que, haber, una, real, justicia, legal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>391</th>\n",
              "      <td>Democracia</td>\n",
              "      <td>(porque, es, el, pilar, fundamental, de, toda,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>655</th>\n",
              "      <td>Respeto</td>\n",
              "      <td>(el, respeto, genera, otros, derechos, √∫tiles,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>935</th>\n",
              "      <td>Respeto / Conservaci√≥n de la naturaleza o medi...</td>\n",
              "      <td>(concebirnos, como, parte, de, la, naturaleza,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>Equidad</td>\n",
              "      <td>(debe, existir, equidad, de, genero, en, mundo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>Equidad</td>\n",
              "      <td>(tiene, que, ver, con, la, idea, de, sociedad,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1014</th>\n",
              "      <td>Estado de Derecho</td>\n",
              "      <td>(el, estado, de, derecho, garantiza, que, los,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>283</th>\n",
              "      <td>Autonom√≠a / Libertad</td>\n",
              "      <td>(capacidad, de, actuar, y, decidir, libremente...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>Estado laico</td>\n",
              "      <td>(fue, categ√≥rico, esto, ,, pues, somos, una, r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>Respeto</td>\n",
              "      <td>(no, hay, respeto, actualmente)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30d58bb5-20f3-4fef-89dc-eaffcf6449b9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-30d58bb5-20f3-4fef-89dc-eaffcf6449b9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-30d58bb5-20f3-4fef-89dc-eaffcf6449b9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-62ba932a-97c6-4163-853a-45ac9d62ab90\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-62ba932a-97c6-4163-853a-45ac9d62ab90')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-62ba932a-97c6-4163-853a-45ac9d62ab90 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                 constitutional_concept  \\\n",
              "1552                                           Justicia   \n",
              "391                                          Democracia   \n",
              "655                                             Respeto   \n",
              "935   Respeto / Conservaci√≥n de la naturaleza o medi...   \n",
              "759                                             Equidad   \n",
              "204                                             Equidad   \n",
              "1014                                  Estado de Derecho   \n",
              "283                                Autonom√≠a / Libertad   \n",
              "220                                        Estado laico   \n",
              "87                                              Respeto   \n",
              "\n",
              "                                               argument  \n",
              "1552  (tiene, que, haber, una, real, justicia, legal...  \n",
              "391   (porque, es, el, pilar, fundamental, de, toda,...  \n",
              "655   (el, respeto, genera, otros, derechos, √∫tiles,...  \n",
              "935   (concebirnos, como, parte, de, la, naturaleza,...  \n",
              "759   (debe, existir, equidad, de, genero, en, mundo...  \n",
              "204   (tiene, que, ver, con, la, idea, de, sociedad,...  \n",
              "1014  (el, estado, de, derecho, garantiza, que, los,...  \n",
              "283   (capacidad, de, actuar, y, decidir, libremente...  \n",
              "220   (fue, categ√≥rico, esto, ,, pues, somos, una, r...  \n",
              "87                      (no, hay, respeto, actualmente)  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "validation_set.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEgOXqAAlg7I"
      },
      "source": [
        "## Features\n",
        "\n",
        "Ahora construiremos el vocabulario con `CountVectorizer` a partir del train split y usaremos BoW como embedding.\n",
        "\n",
        "**Pregunta**: *¬øQu√© pasa con las palabras desconocidas en el split de test?*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tlLX4hPASL2Q"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "bow = CountVectorizer(tokenizer=lambda x: list(x), preprocessor=lambda x: x, token_pattern=None)\n",
        "\n",
        "X_train = pd.DataFrame(\n",
        "    bow.fit_transform(train_set[\"argument\"]).toarray(),\n",
        "    columns=bow.get_feature_names_out()\n",
        ")\n",
        "X_test = pd.DataFrame(\n",
        "    bow.transform(validation_set[\"argument\"]).toarray(),\n",
        "    columns=bow.get_feature_names_out()\n",
        ")\n",
        "\n",
        "XY_train = X_train.astype(float).copy()\n",
        "XY_test = X_test.astype(float).copy()\n",
        "\n",
        "labels = list({doc[1] for doc in dataset})\n",
        "label_map = {label: index for index, label in enumerate(labels)}\n",
        "\n",
        "XY_train[\"constitutional_concept\"] = train_set[\"constitutional_concept\"]\n",
        "XY_train[\"int_class_\"] = train_set[\"constitutional_concept\"].apply(lambda x: label_map[x])\n",
        "\n",
        "XY_test[\"constitutional_concept\"] = validation_set[\"constitutional_concept\"]\n",
        "XY_test[\"int_class_\"] = validation_set[\"constitutional_concept\"].apply(lambda x: label_map[x])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TDmac5KZ6OR"
      },
      "source": [
        "N√∫mero de features (aka. tama√±o del vocabulario):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CpKS8fXXZ6OR",
        "outputId": "f35c48a5-d35f-404a-9f19-eb4287648863"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9552"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_train.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aFWm6ulxlt4w",
        "outputId": "d846be54-2f4f-4078-9721-377da5f6d9f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Pluralismo': 0,\n",
              " 'Democracia': 1,\n",
              " 'Respeto': 2,\n",
              " 'Rep√∫blica': 3,\n",
              " 'Ciudadan√≠a': 4,\n",
              " 'Probidad': 5,\n",
              " 'Libertad': 6,\n",
              " 'Propiedad Privada': 7,\n",
              " 'Desarrollo sustentable': 8,\n",
              " 'Innovaci√≥n / Creatividad': 9,\n",
              " 'Autonom√≠a / Libertad': 10,\n",
              " 'Estado garante': 11,\n",
              " 'Dignidad': 12,\n",
              " 'Plurinacionalismo': 13,\n",
              " 'Emprendimiento libre': 14,\n",
              " 'Igualdad': 15,\n",
              " 'Unidad': 16,\n",
              " 'Tolerancia': 17,\n",
              " 'Subsidiaridad': 18,\n",
              " 'Equidad': 19,\n",
              " 'Familia basada en matrimonio heterosexual': 20,\n",
              " 'Transparencia y publicidad': 21,\n",
              " 'Inclusi√≥n': 22,\n",
              " 'Libertad de conciencia': 23,\n",
              " 'Democracia participativa': 24,\n",
              " 'Paz / Convivencia pac√≠fica': 25,\n",
              " 'Participaci√≥n': 26,\n",
              " 'Descentralizaci√≥n': 27,\n",
              " 'Equidad de g√©nero': 28,\n",
              " 'Desarrollo integral': 29,\n",
              " 'Solidaridad': 30,\n",
              " 'Bien Com√∫n / Comunidad': 31,\n",
              " 'Seguridad': 32,\n",
              " 'Soberan√≠a': 33,\n",
              " 'Derechos humanos': 34,\n",
              " 'Amistad c√≠vica': 35,\n",
              " 'Integraci√≥n': 36,\n",
              " 'Otro': 37,\n",
              " 'Patriotismo': 38,\n",
              " 'Responsabilidad': 39,\n",
              " 'Justicia social': 40,\n",
              " 'Seguridad Social': 41,\n",
              " 'Identidad cultural': 42,\n",
              " 'Respeto / Conservaci√≥n de la naturaleza o medio ambiente': 43,\n",
              " 'Multiculturalidad': 44,\n",
              " 'Desarrollo': 45,\n",
              " 'Estado de Derecho': 46,\n",
              " 'Familia': 47,\n",
              " 'Inclasificable/No corresponde': 48,\n",
              " 'Justicia': 49,\n",
              " 'Estado laico': 50,\n",
              " 'Libertad de expresi√≥n': 51,\n",
              " 'Libertad de culto': 52,\n",
              " 'Diversidad': 53}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Enumeraci√≥n de las clases\n",
        "label_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUB8JEayZ6OS"
      },
      "source": [
        "## Dataset y DataLoader\n",
        "PyTorch ofrece estas dos clases para abstraer la carga de los datos respecto al modelo. As√≠, un objeto `Dataset` entrega datos en forma de tensores para nuestros splits, mientras que `DataLoader` es un iterador para obtener los vectores de nuestro objeto `Dataset`, con la opci√≥n de agruparlos en batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "F-CfyUOxZ6OT",
        "outputId": "a8e596e9-623c-46ce-9184-c1b4019515ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
            "Dimensiones: torch.Size([9552])\n"
          ]
        }
      ],
      "source": [
        "# Ejemplo de tensor BoW\n",
        "sample_tensor = torch.tensor(X_train.iloc[2].values.astype(float)).to(torch.float32)\n",
        "print(sample_tensor)\n",
        "print(f\"Dimensiones: {sample_tensor.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZHP_enMZ6OU"
      },
      "source": [
        "Creamos nuestro objeto `Dataset` seg√∫n dataset y features, entregando cada $x$ e $y$ en forma de tensor `float32`.\n",
        "\n",
        "**Ojo aqu√≠ con los tipos**, es importante hacer esta conversi√≥n para luego alimentar los datos a la red neuronal, el tipo de `float` tambi√©n debe coincidir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HiGVu3TcWQor"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "class MyDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, bow_cols):\n",
        "        self.data = data\n",
        "        self.bow_cols = bow_cols\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = int(self.data.loc[index, \"int_class_\"])\n",
        "        x_bow = (torch.tensor(self.data.loc[index, self.bow_cols] # Importante: Obtenemos el vector x_{index}\n",
        "                              .values.astype(float)) # lo convertimos a float, luego a tensor\n",
        "                              .to(torch.float32)) # y fijamos el tipo float32\n",
        "        return x_bow, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oO6qfKRjZ6OU"
      },
      "source": [
        "Ahora podemos crear nuestros DataLoaders. Para esto creamos primero dos Datasets `MyDataset` con los splits que creamos en la secci√≥n anterior, y luego dos DataLoaders a partir de √©stos. Tambi√©n fijamos el batch size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mU-cx2vdWQ4z"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    MyDataset(data = XY_train, bow_cols = X_train.columns), # Dataset de tensores con XY_train\n",
        "    batch_size = batch_size, num_workers = 1, shuffle=False)\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    MyDataset(data = XY_test, bow_cols = X_test.columns),   # Dataset de tensores con XY_test\n",
        "    batch_size = batch_size, num_workers = 1, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5WUbpwDlvtX"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7fGtxVWbWtCX"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class ArgumentClassifier(nn.Module):\n",
        "    # Par√°metros\n",
        "    def __init__(self,\n",
        "                 dim_vocab,\n",
        "                 num_classes,\n",
        "                 dim_hidden_input,\n",
        "                 dim_hidden_output):\n",
        "\n",
        "        super(ArgumentClassifier, self).__init__()\n",
        "\n",
        "        torch.manual_seed(42)\n",
        "\n",
        "        # Definimos las capas del modelo\n",
        "\n",
        "        # Primera capa\n",
        "        self.first_layer = nn.Linear(dim_vocab, dim_hidden_input)\n",
        "\n",
        "        # Capa oculta\n",
        "        self.hidden_layer = nn.Linear(dim_hidden_input, dim_hidden_output)\n",
        "\n",
        "        # √öltima capa\n",
        "        self.last_layer = nn.Linear(dim_hidden_output, num_classes)\n",
        "\n",
        "        # Funci√≥n de activaci√≥n\n",
        "        self.relu = nn.ReLU(inplace=False)\n",
        "\n",
        "    def forward(self, xs_bow):\n",
        "\n",
        "      # Hacemos el forward-pass\n",
        "      first_state = self.first_layer(xs_bow)\n",
        "      first_state = self.relu(first_state)\n",
        "\n",
        "      hidden_state = self.hidden_layer(first_state)\n",
        "      hidden_state = self.relu(hidden_state)\n",
        "\n",
        "      last_state = self.last_layer(hidden_state)\n",
        "\n",
        "      return last_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVq1K4tGl1cH"
      },
      "source": [
        "## Entrenamiento\n",
        "Ahora creamos funciones que nos ayuden a entrenar y validar el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BnkmOmBp9DEf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_loss(net, iterator, criterion, device):\n",
        "    net.eval()\n",
        "    total_loss = 0\n",
        "    num_evals = 0\n",
        "    with torch.no_grad():\n",
        "        for xs_bow, labels in iterator:\n",
        "            xs_bow, labels = xs_bow.to(device), labels.to(device)\n",
        "\n",
        "            logits = net(xs_bow)\n",
        "\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            total_loss += loss.item() * xs_bow.shape[0]\n",
        "            num_evals += xs_bow.shape[0]\n",
        "\n",
        "    return total_loss / num_evals\n",
        "\n",
        "def get_preds_tests_nn(net, iterator, device):\n",
        "  net.eval()\n",
        "  preds, tests = [], []\n",
        "  with torch.no_grad():\n",
        "    for xs_bow, labels in iterator:\n",
        "      xs_bow, labels = xs_bow.to(device), labels.to(device)\n",
        "\n",
        "      logits = net(xs_bow)\n",
        "\n",
        "      soft_probs = nn.Sigmoid()(logits)\n",
        "\n",
        "      preds += np.argmax(soft_probs.tolist(), axis=1).tolist()\n",
        "      tests += labels.tolist()\n",
        "\n",
        "    return np.array(preds), np.array(tests)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La1LIXdMZ6OY"
      },
      "source": [
        "Ahora por fin tenemos todo lo necesario para entrenar el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlhKqOlIz9l-"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "params = {\n",
        "    \"dim_vocab\": len(train_loader.dataset.bow_cols),\n",
        "    \"num_classes\": len(labels),\n",
        "    \"dim_hidden_input\": 200,\n",
        "    \"dim_hidden_output\": 100,\n",
        "    \"learning_rate\": 0.5,\n",
        "    \"epochs\": 15\n",
        "}\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = ArgumentClassifier(\n",
        "    dim_vocab=params[\"dim_vocab\"],\n",
        "    num_classes=params[\"num_classes\"],\n",
        "    dim_hidden_input=params[\"dim_hidden_input\"],\n",
        "    dim_hidden_output=params[\"dim_hidden_output\"]\n",
        ").to(device)\n",
        "\n",
        "# Loss = Cross-entropy\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "# optimizador = SGD: Stochastic-gradient Descent\n",
        "optimizer = optim.SGD(model.parameters(), lr = params[\"learning_rate\"])\n",
        "\n",
        "# numero de epocas de entrenamiento\n",
        "epochs = params[\"epochs\"]\n",
        "import time\n",
        "for epoch in range(epochs):\n",
        "  start_time = time.time()\n",
        "  for (xs_bow, preds) in train_loader:\n",
        "\n",
        "    optimizer.zero_grad() # Optimizador: reiniciar las derivadas de los par√°metros a 0\n",
        "\n",
        "    xs_bow, preds = xs_bow.to(device), preds.to(device) # Pasar nuestros tensores a la GPU\n",
        "\n",
        "    logits = model(xs_bow) # Calcular las predicciones\n",
        "\n",
        "    loss = criterion(logits, preds) # Calcular la loss entre predicciones y ground truth\n",
        "\n",
        "    loss.backward() # Calcular el gradiente de la loss respecto a los par√°metros\n",
        "\n",
        "    optimizer.step() # Actualizar los par√°metros, en la direcci√≥n del gradiente\n",
        "\n",
        "\n",
        "  train_loss = get_loss(model, train_loader, criterion, device)\n",
        "  y_preds, y_tests = get_preds_tests_nn(model, train_loader, device)\n",
        "  train_acc = (y_preds == y_tests).sum() / y_preds.shape[0]\n",
        "\n",
        "  validation_loss = get_loss(model, test_loader, criterion, device)\n",
        "  y_preds, y_tests = get_preds_tests_nn(model, test_loader, device)\n",
        "  validation_acc = (y_preds == y_tests).sum() / y_preds.shape[0]\n",
        "\n",
        "  secs = int(time.time() - start_time)\n",
        "  mins = secs // 60\n",
        "  secs = secs % 60\n",
        "\n",
        "  print(f\"Epoca {epoch} completada en {mins} minutos, {secs} segundos\")\n",
        "  print(f\"Train Loss: {train_loss}, Train Accuracy: {train_acc}\")\n",
        "  print(f\"Valid. Loss: {validation_loss}, Valid. Accuracy: {validation_acc}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30684,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}