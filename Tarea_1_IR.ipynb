{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiegoEspinozaoss/Natural_Language_Processing_CC6205-1/blob/main/Tarea_1_IR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxrkZWMLZB8z"
      },
      "source": [
        "# Tarea 1: Introducci√≥n, Modelos de Espacio Vectorial, Recuperaci√≥n de Informaci√≥n y Modelos de Lenguaje\n",
        "\n",
        "**Procesamiento de Lenguaje Natural (CC6205-1 - Oto√±o 2025)**\n",
        "\n",
        "## Tarjeta de Identificaci√≥n\n",
        "\n",
        "- **Nombre(s):** ```Diego Espinoza, Juan Mi√±o, Emilio Torres```\n",
        "- **Fecha l√≠mite de entrega üìÜ:** 15 de abril de 2025\n",
        "- **Tiempo estimado de dedicaci√≥n:** 4 horas\n",
        "\n",
        "---\n",
        "\n",
        "## üìå Instrucciones\n",
        "\n",
        "¬°Bienvenid@s a la primera tarea del curso de *Natural Language Processing* (NLP)!\n",
        "\n",
        "El objetivo de esta tarea es evaluar los conceptos te√≥ricos de las primeras semanas de clases, centr√°ndose en:\n",
        "\n",
        "- **Recuperaci√≥n de Informaci√≥n (IR)**\n",
        "- **Modelos de Espacio Vectorial**\n",
        "- **Modelos de Lenguaje**\n",
        "\n",
        "Si a√∫n no has revisado el contenido correspondiente, se recomienda consultar las referencias disponibles al final del documento.\n",
        "\n",
        "### üì¢ Consideraciones generales\n",
        "\n",
        "‚úÖ La tarea debe realizarse en **grupos de hasta 3 personas**.\n",
        "\n",
        "‚úÖ La entrega debe realizarse a trav√©s de **U-Cursos**, a m√°s tardar en la fecha estipulada. **No se aceptar√°n entregas atrasadas.**\n",
        "\n",
        "‚úÖ El formato de entrega es este mismo **Jupyter Notebook**.\n",
        "\n",
        "‚úÖ Su c√≥digo ser√° ejecutado al momento de la revisi√≥n. **Verifiquen que no tenga errores de compilaci√≥n.**\n",
        "\n",
        "‚úÖ Es obligatorio completar la **Tarjeta de Identificaci√≥n**. **No se asignar√° nota sin ella.**\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Material de Referencia\n",
        "\n",
        "### üìÑ Diapositivas del curso\n",
        "\n",
        "- [Introducci√≥n al curso](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-introduction.pdf)\n",
        "- [Modelos de Espacio Vectorial y Recuperaci√≥n de Informaci√≥n](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-IR.pdf)\n",
        "- [Modelos Probabil√≠sticos de Lenguaje](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-PLM.pdf)\n",
        "\n",
        "### üì∫ Videos del curso\n",
        "\n",
        "- **Introducci√≥n**: [Parte 1](https://www.youtube.com/watch?v=HEKTNOttGvU) | [Parte 2](https://www.youtube.com/watch?v=P8cwnI-f-Kg)\n",
        "- **Recuperaci√≥n de Informaci√≥n**: [Parte 1](https://www.youtube.com/watch?v=FXIVClF370w&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=3) | [Parte 2](https://www.youtube.com/watch?v=f8nG1EMmPZk&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=3)\n",
        "- **Modelos Probabil√≠sticos de Lenguaje**: [Parte 1](https://www.youtube.com/watch?v=9E2jJ6kcb4Y&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=3) | [Parte 2](https://www.youtube.com/watch?v=ZWqbEQXLra0&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=5) | [Parte 3](https://www.youtube.com/watch?v=tsumFqwFlaA&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=6) | [Parte 4](https://www.youtube.com/watch?v=s3TWdv4sqkg&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJq)\n",
        "\n",
        "---\n",
        "\n",
        "üìå **Recuerda:** La claridad y organizaci√≥n en la entrega son clave para una mejor evaluaci√≥n. Incluir analisis apropiado. ¬°Mucho √©xito! üöÄ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7w4BT1qmChV"
      },
      "source": [
        "## P1. Tokenizaci√≥n\n",
        "\n",
        "En el primer ejercicio veremos la dificultad de tokenizar textos no estructurados, destacando la importancia de tener librer√≠as que realicen este trabajo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlgSZrB2oe1H",
        "outputId": "9699523d-c2e5-4dc7-a094-26caab6e8e4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ignorando conexi√≥n drive-colab\n"
          ]
        }
      ],
      "source": [
        "# En caso de desarrollar la tarea desde colab, con el siguiente c√≥digo podemos cargar los archivos desde drive:\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(\"/content/drive\", force_remount=True)\n",
        "    path = '/content/drive/MyDrive/nlp/oh_algoritmo.txt'\n",
        "except:\n",
        "    print('Ignorando conexi√≥n drive-colab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCKFrnZcoy2F"
      },
      "source": [
        "Ejecute el c√≥digo a continuaci√≥n para cargar el ejemplo. Recuerde realizar la modificaci√≥n al directorio en caso que el archivo no se encuentre en el mismo directorio del Jupyter Notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9CteGwEmDKw",
        "outputId": "4ab9ef8a-c16e-4580-f726-6d8895ad0727"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Letra de \"¬°Oh, Algoritmo!\" ft. Nora Erez]\n",
            "\n",
            "[Refr√°n: Jorge Drexler]\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "\n",
            "[Estribillo: Jorge Drexler]\n",
            "Dime qu√© debo cantar\n",
            "Oh, algoritmo\n",
            "S√© que lo sabes mejor\n",
            "Incluso que yo mismo\n",
            "\n",
            "[Verso 1: Nora Erez]\n",
            "Wait, what's that money that you spent?\n",
            "What's that sitting on your plate?\n",
            "Do you want what you've been fed?\n",
            "Are you the fish or bait?\n",
            "Mmm, I'm on the top of the roof and I feel like a jail\n",
            "Rather not pay the bail\n",
            "To dangerous people with blood on their faces\n",
            "So I'm sharing a cell with the masses\n",
            "The underground always strive for the main\n",
            "Streaming like Grande's big-ass ring\n",
            "Screaming: I'll write you out my will\n",
            "Conscious is free, but not the will\n",
            "Conscious is free, but not the will\n",
            "You might also like\n",
            "Amor al Arte\n",
            "Jorge Drexler\n",
            "Tinta y Tiempo\n",
            "Jorge Drexler\n",
            "Asilo\n",
            "Jorge Drexler\n",
            "[Pre-Estribillo: Nora Erez]\n",
            "So if you want me to want what I believe that I want\n",
            "Can I choose to quit?\n",
            "\n",
            "[Estribillo: Jorge Drexler]\n",
            "Dime qu√© debo cantar\n",
            "Oh, algoritmo\n",
            "S√© que lo sabes mejor\n",
            "Incluso que yo mismo\n",
            "\n",
            "[Verso 2: Jorge Drexler]\n",
            "Por ejemplo, esta canci√≥n\n",
            "¬øQu√© algoritmo la pari√≥?\n",
            "Me pregunto si fui yo\n",
            "¬øLa elegiste o te eligi√≥?\n",
            "\n",
            "[Verso 3: Jorge Drexler]\n",
            "Dios era la letra chica al final del papel\n",
            "Ya no contamos con √âl\n",
            "Fin de la Luna de miel\n",
            "Y el libre albedr√≠o es un cauce vac√≠o\n",
            "Un barco que no tiene r√≠o\n",
            "Ni timonel\n",
            "\n",
            "[Verso 4: Jorge Drexler]\n",
            "Todos aplauden, t√∫ tambi√©n\n",
            "Pero no queda claro qui√©n\n",
            "Tiene del mango a la sart√©n\n",
            "Del sacrificio\n",
            "Piel o silicio\n",
            "Y el precipicio\n",
            "Dice: Ven, ven, ven\n",
            "[Refr√°n: Jorge Drexler]\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Dime qu√© debo cantar)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Oh, algoritmo)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(S√© que lo sabes mejor)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Incluso que yo mismo)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Dime qu√© debo cantar)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Oh, algoritmo)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(S√© que lo sabes mejor)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Incluso que yo mismo)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Wow)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # Abre el archivo en modo lectura (\"r\")\n",
        "    with open(\"oh_algoritmo.txt\", \"r\") as archivo:\n",
        "        # Lee el contenido del archivo\n",
        "        texto = archivo.read()\n",
        "        # Imprime el contenido\n",
        "        print(texto)\n",
        "except FileNotFoundError:\n",
        "    print(\"El archivo no se encuentra.\")\n",
        "except Exception as e:\n",
        "    print(\"Ocurri√≥ un error:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPSSO2kJoArL"
      },
      "source": [
        "Fuente: https://genius.com/Jorge-drexler-oh-algoritmo-lyrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fG0hLbHg9dn"
      },
      "source": [
        "### Pregunta 1.a (0.25 puntos)\n",
        "\n",
        "Dise√±e una funci√≥n **`get_tokens()`** que reciba un texto y entregue una lista con sus tokens. Es libre de elegir la forma de tokenizar mientras no utilice librer√≠as con tokenizadores ya implementados. Puede utilizar la librer√≠a **re** importada para trabajar s√≠mbolos. Explique su razonamiento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiRMkdjwazFT"
      },
      "outputs": [],
      "source": [
        "def get_tokens(texto):\n",
        "    \"\"\"\n",
        "    b√°sicamente lo que hace la funci√≥n es tomar un texto\n",
        "    y ver descartar todos los caracteres que no son palabras,\n",
        "    es decir, descartar toda aquello que no pueda ser expresado\n",
        "    como una serie continua de vocales o consonantes. \n",
        "    \"\"\"\n",
        "    tokens = re.findall(r'\\b\\w+\\b', texto)\n",
        "    return tokens\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "hDBZn4kOm7uH"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Letra',\n",
              " 'de',\n",
              " 'Oh',\n",
              " 'Algoritmo',\n",
              " 'ft',\n",
              " 'Nora',\n",
              " 'Erez',\n",
              " 'Refr√°n',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Estribillo',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Dime',\n",
              " 'qu√©',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " 'Oh',\n",
              " 'algoritmo',\n",
              " 'S√©',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " 'Verso',\n",
              " '1',\n",
              " 'Nora',\n",
              " 'Erez',\n",
              " 'Wait',\n",
              " 'what',\n",
              " 's',\n",
              " 'that',\n",
              " 'money',\n",
              " 'that',\n",
              " 'you',\n",
              " 'spent',\n",
              " 'What',\n",
              " 's',\n",
              " 'that',\n",
              " 'sitting',\n",
              " 'on',\n",
              " 'your',\n",
              " 'plate',\n",
              " 'Do',\n",
              " 'you',\n",
              " 'want',\n",
              " 'what',\n",
              " 'you',\n",
              " 've',\n",
              " 'been',\n",
              " 'fed',\n",
              " 'Are',\n",
              " 'you',\n",
              " 'the',\n",
              " 'fish',\n",
              " 'or',\n",
              " 'bait',\n",
              " 'Mmm',\n",
              " 'I',\n",
              " 'm',\n",
              " 'on',\n",
              " 'the',\n",
              " 'top',\n",
              " 'of',\n",
              " 'the',\n",
              " 'roof',\n",
              " 'and',\n",
              " 'I',\n",
              " 'feel',\n",
              " 'like',\n",
              " 'a',\n",
              " 'jail',\n",
              " 'Rather',\n",
              " 'not',\n",
              " 'pay',\n",
              " 'the',\n",
              " 'bail',\n",
              " 'To',\n",
              " 'dangerous',\n",
              " 'people',\n",
              " 'with',\n",
              " 'blood',\n",
              " 'on',\n",
              " 'their',\n",
              " 'faces',\n",
              " 'So',\n",
              " 'I',\n",
              " 'm',\n",
              " 'sharing',\n",
              " 'a',\n",
              " 'cell',\n",
              " 'with',\n",
              " 'the',\n",
              " 'masses',\n",
              " 'The',\n",
              " 'underground',\n",
              " 'always',\n",
              " 'strive',\n",
              " 'for',\n",
              " 'the',\n",
              " 'main',\n",
              " 'Streaming',\n",
              " 'like',\n",
              " 'Grande',\n",
              " 's',\n",
              " 'big',\n",
              " 'ass',\n",
              " 'ring',\n",
              " 'Screaming',\n",
              " 'I',\n",
              " 'll',\n",
              " 'write',\n",
              " 'you',\n",
              " 'out',\n",
              " 'my',\n",
              " 'will',\n",
              " 'Conscious',\n",
              " 'is',\n",
              " 'free',\n",
              " 'but',\n",
              " 'not',\n",
              " 'the',\n",
              " 'will',\n",
              " 'Conscious',\n",
              " 'is',\n",
              " 'free',\n",
              " 'but',\n",
              " 'not',\n",
              " 'the',\n",
              " 'will',\n",
              " 'You',\n",
              " 'might',\n",
              " 'also',\n",
              " 'like',\n",
              " 'Amor',\n",
              " 'al',\n",
              " 'Arte',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Tinta',\n",
              " 'y',\n",
              " 'Tiempo',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Asilo',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Pre',\n",
              " 'Estribillo',\n",
              " 'Nora',\n",
              " 'Erez',\n",
              " 'So',\n",
              " 'if',\n",
              " 'you',\n",
              " 'want',\n",
              " 'me',\n",
              " 'to',\n",
              " 'want',\n",
              " 'what',\n",
              " 'I',\n",
              " 'believe',\n",
              " 'that',\n",
              " 'I',\n",
              " 'want',\n",
              " 'Can',\n",
              " 'I',\n",
              " 'choose',\n",
              " 'to',\n",
              " 'quit',\n",
              " 'Estribillo',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Dime',\n",
              " 'qu√©',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " 'Oh',\n",
              " 'algoritmo',\n",
              " 'S√©',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " 'Verso',\n",
              " '2',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Por',\n",
              " 'ejemplo',\n",
              " 'esta',\n",
              " 'canci√≥n',\n",
              " 'Qu√©',\n",
              " 'algoritmo',\n",
              " 'la',\n",
              " 'pari√≥',\n",
              " 'Me',\n",
              " 'pregunto',\n",
              " 'si',\n",
              " 'fui',\n",
              " 'yo',\n",
              " 'La',\n",
              " 'elegiste',\n",
              " 'o',\n",
              " 'te',\n",
              " 'eligi√≥',\n",
              " 'Verso',\n",
              " '3',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Dios',\n",
              " 'era',\n",
              " 'la',\n",
              " 'letra',\n",
              " 'chica',\n",
              " 'al',\n",
              " 'final',\n",
              " 'del',\n",
              " 'papel',\n",
              " 'Ya',\n",
              " 'no',\n",
              " 'contamos',\n",
              " 'con',\n",
              " '√âl',\n",
              " 'Fin',\n",
              " 'de',\n",
              " 'la',\n",
              " 'Luna',\n",
              " 'de',\n",
              " 'miel',\n",
              " 'Y',\n",
              " 'el',\n",
              " 'libre',\n",
              " 'albedr√≠o',\n",
              " 'es',\n",
              " 'un',\n",
              " 'cauce',\n",
              " 'vac√≠o',\n",
              " 'Un',\n",
              " 'barco',\n",
              " 'que',\n",
              " 'no',\n",
              " 'tiene',\n",
              " 'r√≠o',\n",
              " 'Ni',\n",
              " 'timonel',\n",
              " 'Verso',\n",
              " '4',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Todos',\n",
              " 'aplauden',\n",
              " 't√∫',\n",
              " 'tambi√©n',\n",
              " 'Pero',\n",
              " 'no',\n",
              " 'queda',\n",
              " 'claro',\n",
              " 'qui√©n',\n",
              " 'Tiene',\n",
              " 'del',\n",
              " 'mango',\n",
              " 'a',\n",
              " 'la',\n",
              " 'sart√©n',\n",
              " 'Del',\n",
              " 'sacrificio',\n",
              " 'Piel',\n",
              " 'o',\n",
              " 'silicio',\n",
              " 'Y',\n",
              " 'el',\n",
              " 'precipicio',\n",
              " 'Dice',\n",
              " 'Ven',\n",
              " 'ven',\n",
              " 'ven',\n",
              " 'Refr√°n',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Dime',\n",
              " 'qu√©',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Oh',\n",
              " 'algoritmo',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'S√©',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Dime',\n",
              " 'qu√©',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Oh',\n",
              " 'algoritmo',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'S√©',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Wow']"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens = get_tokens(texto)\n",
        "tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CpZKljrotLa"
      },
      "source": [
        "### Pregunta 1.b (0.25 puntos)\n",
        "Explique su implementaci√≥n aqu√≠:\n",
        "La implementaci√≥n ... Esta librer√≠a \"re\" cuyo m√©todo findall(r'\\b\\w+\\b',texto) es tal que; \\b es un l√≠mite de palabra (asegura que no tomemos fragmentos de palabras como partes de los tokens), \\w+ captura una o m√°s letras, n√∫meros o guiones bajos (es decir, palabras). Esto asegura que cada token sea una secuencia de caracteres alfanum√©ricos. Esta expresi√≥n regular no captura signos de puntuaci√≥n ni espacios, solo las palabras. Por ejemplo, si tenemos \n",
        "\n",
        ">movie_str = \"the evening shows start at 7:00pm and 10:15pm\"\n",
        "\n",
        ">matches = re.findall(r\"([\\d:,.]+)(am|pm)?\", movie_str)\n",
        "\n",
        "devolver√° lo siguiente: \n",
        "\n",
        ">[(\"7:00\", \"pm\"), (\"10:15\", \"pm\")]. \n",
        "\n",
        "Entonces la sintaxis general de re.findall es la [siguiente](https://www.codecademy.com/resources/docs/python/regex/findall): re.findall(<pattern>, string), donde pattern vendr√≠a siendo el patr√≥n que puede incluir un string, un c√≥digo de clase de car√°cter como /w, /s o /d, o bien un s√≠mbolo regular como $, | y ^."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIwAKWZvofEp"
      },
      "source": [
        "Implementaci√≥n con la libreria NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GR2Z0lnnPB9",
        "outputId": "65500454-2fbd-4e49-9e45-71fd08a8f6e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[',\n",
              " 'Letra',\n",
              " 'de',\n",
              " '\"¬°',\n",
              " 'Oh',\n",
              " ',',\n",
              " 'Algoritmo',\n",
              " '!\"',\n",
              " 'ft',\n",
              " '.',\n",
              " 'Nora',\n",
              " 'Erez',\n",
              " ']',\n",
              " '[',\n",
              " 'Refr√°n',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '[',\n",
              " 'Estribillo',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " 'Dime',\n",
              " 'qu√©',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " 'Oh',\n",
              " ',',\n",
              " 'algoritmo',\n",
              " 'S√©',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " '[',\n",
              " 'Verso',\n",
              " '1',\n",
              " ':',\n",
              " 'Nora',\n",
              " 'Erez',\n",
              " ']',\n",
              " 'Wait',\n",
              " ',',\n",
              " 'what',\n",
              " \"'\",\n",
              " 's',\n",
              " 'that',\n",
              " 'money',\n",
              " 'that',\n",
              " 'you',\n",
              " 'spent',\n",
              " '?',\n",
              " 'What',\n",
              " \"'\",\n",
              " 's',\n",
              " 'that',\n",
              " 'sitting',\n",
              " 'on',\n",
              " 'your',\n",
              " 'plate',\n",
              " '?',\n",
              " 'Do',\n",
              " 'you',\n",
              " 'want',\n",
              " 'what',\n",
              " 'you',\n",
              " \"'\",\n",
              " 've',\n",
              " 'been',\n",
              " 'fed',\n",
              " '?',\n",
              " 'Are',\n",
              " 'you',\n",
              " 'the',\n",
              " 'fish',\n",
              " 'or',\n",
              " 'bait',\n",
              " '?',\n",
              " 'Mmm',\n",
              " ',',\n",
              " 'I',\n",
              " \"'\",\n",
              " 'm',\n",
              " 'on',\n",
              " 'the',\n",
              " 'top',\n",
              " 'of',\n",
              " 'the',\n",
              " 'roof',\n",
              " 'and',\n",
              " 'I',\n",
              " 'feel',\n",
              " 'like',\n",
              " 'a',\n",
              " 'jail',\n",
              " 'Rather',\n",
              " 'not',\n",
              " 'pay',\n",
              " 'the',\n",
              " 'bail',\n",
              " 'To',\n",
              " 'dangerous',\n",
              " 'people',\n",
              " 'with',\n",
              " 'blood',\n",
              " 'on',\n",
              " 'their',\n",
              " 'faces',\n",
              " 'So',\n",
              " 'I',\n",
              " \"'\",\n",
              " 'm',\n",
              " 'sharing',\n",
              " 'a',\n",
              " 'cell',\n",
              " 'with',\n",
              " 'the',\n",
              " 'masses',\n",
              " 'The',\n",
              " 'underground',\n",
              " 'always',\n",
              " 'strive',\n",
              " 'for',\n",
              " 'the',\n",
              " 'main',\n",
              " 'Streaming',\n",
              " 'like',\n",
              " 'Grande',\n",
              " \"'\",\n",
              " 's',\n",
              " 'big',\n",
              " '-',\n",
              " 'ass',\n",
              " 'ring',\n",
              " 'Screaming',\n",
              " ':',\n",
              " 'I',\n",
              " \"'\",\n",
              " 'll',\n",
              " 'write',\n",
              " 'you',\n",
              " 'out',\n",
              " 'my',\n",
              " 'will',\n",
              " 'Conscious',\n",
              " 'is',\n",
              " 'free',\n",
              " ',',\n",
              " 'but',\n",
              " 'not',\n",
              " 'the',\n",
              " 'will',\n",
              " 'Conscious',\n",
              " 'is',\n",
              " 'free',\n",
              " ',',\n",
              " 'but',\n",
              " 'not',\n",
              " 'the',\n",
              " 'will',\n",
              " 'You',\n",
              " 'might',\n",
              " 'also',\n",
              " 'like',\n",
              " 'Amor',\n",
              " 'al',\n",
              " 'Arte',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Tinta',\n",
              " 'y',\n",
              " 'Tiempo',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Asilo',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " '[',\n",
              " 'Pre',\n",
              " '-',\n",
              " 'Estribillo',\n",
              " ':',\n",
              " 'Nora',\n",
              " 'Erez',\n",
              " ']',\n",
              " 'So',\n",
              " 'if',\n",
              " 'you',\n",
              " 'want',\n",
              " 'me',\n",
              " 'to',\n",
              " 'want',\n",
              " 'what',\n",
              " 'I',\n",
              " 'believe',\n",
              " 'that',\n",
              " 'I',\n",
              " 'want',\n",
              " 'Can',\n",
              " 'I',\n",
              " 'choose',\n",
              " 'to',\n",
              " 'quit',\n",
              " '?',\n",
              " '[',\n",
              " 'Estribillo',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " 'Dime',\n",
              " 'qu√©',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " 'Oh',\n",
              " ',',\n",
              " 'algoritmo',\n",
              " 'S√©',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " '[',\n",
              " 'Verso',\n",
              " '2',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " 'Por',\n",
              " 'ejemplo',\n",
              " ',',\n",
              " 'esta',\n",
              " 'canci√≥n',\n",
              " '¬ø',\n",
              " 'Qu√©',\n",
              " 'algoritmo',\n",
              " 'la',\n",
              " 'pari√≥',\n",
              " '?',\n",
              " 'Me',\n",
              " 'pregunto',\n",
              " 'si',\n",
              " 'fui',\n",
              " 'yo',\n",
              " '¬ø',\n",
              " 'La',\n",
              " 'elegiste',\n",
              " 'o',\n",
              " 'te',\n",
              " 'eligi√≥',\n",
              " '?',\n",
              " '[',\n",
              " 'Verso',\n",
              " '3',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " 'Dios',\n",
              " 'era',\n",
              " 'la',\n",
              " 'letra',\n",
              " 'chica',\n",
              " 'al',\n",
              " 'final',\n",
              " 'del',\n",
              " 'papel',\n",
              " 'Ya',\n",
              " 'no',\n",
              " 'contamos',\n",
              " 'con',\n",
              " '√âl',\n",
              " 'Fin',\n",
              " 'de',\n",
              " 'la',\n",
              " 'Luna',\n",
              " 'de',\n",
              " 'miel',\n",
              " 'Y',\n",
              " 'el',\n",
              " 'libre',\n",
              " 'albedr√≠o',\n",
              " 'es',\n",
              " 'un',\n",
              " 'cauce',\n",
              " 'vac√≠o',\n",
              " 'Un',\n",
              " 'barco',\n",
              " 'que',\n",
              " 'no',\n",
              " 'tiene',\n",
              " 'r√≠o',\n",
              " 'Ni',\n",
              " 'timonel',\n",
              " '[',\n",
              " 'Verso',\n",
              " '4',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " 'Todos',\n",
              " 'aplauden',\n",
              " ',',\n",
              " 't√∫',\n",
              " 'tambi√©n',\n",
              " 'Pero',\n",
              " 'no',\n",
              " 'queda',\n",
              " 'claro',\n",
              " 'qui√©n',\n",
              " 'Tiene',\n",
              " 'del',\n",
              " 'mango',\n",
              " 'a',\n",
              " 'la',\n",
              " 'sart√©n',\n",
              " 'Del',\n",
              " 'sacrificio',\n",
              " 'Piel',\n",
              " 'o',\n",
              " 'silicio',\n",
              " 'Y',\n",
              " 'el',\n",
              " 'precipicio',\n",
              " 'Dice',\n",
              " ':',\n",
              " 'Ven',\n",
              " ',',\n",
              " 'ven',\n",
              " ',',\n",
              " 'ven',\n",
              " '[',\n",
              " 'Refr√°n',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Dime',\n",
              " 'qu√©',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " ')',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Oh',\n",
              " ',',\n",
              " 'algoritmo',\n",
              " ')',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'S√©',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " ')',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " ')',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Dime',\n",
              " 'qu√©',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " ')',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Oh',\n",
              " ',',\n",
              " 'algoritmo',\n",
              " ')',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'S√©',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " ')',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " ')',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Wow',\n",
              " ')']"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "nltk_tokens = wordpunct_tokenize(texto)\n",
        "nltk_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so3P4OeGn-qo"
      },
      "source": [
        "### Pregunta 1.c (0.5 puntos)\n",
        "¬øQu√© diferencias y similitudes encontrase al comparar la funci√≥n de tokenizaci√≥n creada manualmente por ti contra la implementaci√≥n de NLTK, al tokenizar la letra de la canci√≥n \"Oh, algoritmo\"?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E12BZ29JoFCp"
      },
      "source": [
        ">Una diferencia que encontr√© es que en el caso de la funci√≥n de tokenizaci√≥n creada a mano no se aceptan tokens como simbolos tales como \"?\", \")\", \"]\", etc., mientras que en el NLTK s√≠. Una similitud es que parecen respetar el orden del texto original, es decir, parecen guardar elementos secuencialmente en orden de aparici√≥n a medida que van leyendo el teto. Por otro lado, en la funci√≥n que defin√≠ yo es necesario especificar los caracteres que se consideran v√°lidos, mientras que en la NLTK no. As√≠ mismo, la funci√≥n m√≠a aceptaba letras como √¢ o √Ç, mientras que la NLTK no, quiz√°s debido a su enfoque. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmUULnB6hWcl"
      },
      "source": [
        "## P2. Stemming y Stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LskhxOLdpT9q"
      },
      "source": [
        "En esta secci√≥n debera implementar funciones de stemming y stopwords basado en lo visto en clase. En la siguiente celda tiene el corpus que usara en esta secci√≥n:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Recordemos que las **stopwords** son palabras muy comunes en un idioma, como ‚Äúel‚Äù, ‚Äúde‚Äù o ‚Äúy‚Äù en espa√±ol, que suelen eliminarse en tareas de procesamiento de texto porque no aportan informaci√≥n relevante para el an√°lisis. Por otro lado, el **stemming** es una t√©cnica que reduce las palabras a su ra√≠z o forma base, aunque esta ra√≠z no siempre sea una palabra real, con el objetivo de agrupar variantes como ‚Äújugando‚Äù, ‚Äújugar√°‚Äù o ‚Äújugaban‚Äù bajo un mismo \"stem\" como ‚Äújug‚Äù. Ambas t√©cnicas ayudan a simplificar el texto y reducir la dimensionalidad en modelos de lenguaje."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "hj07_CmwhYxk"
      },
      "outputs": [],
      "source": [
        "# Corpus en espa√±ol\n",
        "corpus_espanol = [\n",
        "    \"¬øQui√©n quiere que yo quiera lo que creo que quiero?\",\n",
        "    \"Dime qu√© debo cantar\",\n",
        "    \"S√© que lo sabes mejor\"\n",
        "]\n",
        "\n",
        "# Corpus en ingl√©s\n",
        "corpus_ingles = [\n",
        "    \"What's that sitting on your plate?\",\n",
        "    \"Do you want what you've been fed?\",\n",
        "    \"Are you the fish or bait?\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xRyOVbVWwJ5"
      },
      "source": [
        "### Pregunta 2.a (0.5 puntos)\n",
        "Implemente una funci√≥n **`get_vocab()`** que extraiga los tokens de un corpus. Puede utilizar la funci√≥n de la secci√≥n anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "F-727zL3ptDZ"
      },
      "outputs": [],
      "source": [
        "def get_vocab(corpus):\n",
        "    \"\"\"\n",
        "    Tokenizamos todo el corpus y\n",
        "    luego extraemos solo los tokens alfab√©ticos.\n",
        "    \"\"\"\n",
        "    s = []\n",
        "    for i in range(len(corpus)):\n",
        "        tokens = wordpunct_tokenize(corpus[i])\n",
        "        s += [t.lower() for t in tokens if t.isalpha()]\n",
        "    return s\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ge2cPS7fqYXy",
        "outputId": "2b5f148c-15cc-461a-c12e-ca9562f2639e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'dime',\n",
              " 'qu√©',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " 's√©',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor']"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_espanol = get_vocab(corpus_espanol)\n",
        "vocab_espanol"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCFtzHUbzJqt"
      },
      "source": [
        "Resultado esperado (el orden puede variar):\n",
        "```\n",
        "['yo', 'debo', 'creo', 'Dime', 'lo', 'cantar', 'mejor', 'S√©', 'que', 'quiere', 'quiero', 'sabes', 'Qui√©n', 'quiera', 'qu√©']\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apRK_d8uqlSm",
        "outputId": "b6460bf1-b8bf-471b-e97f-1789e7367348"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['what',\n",
              " 's',\n",
              " 'that',\n",
              " 'sitting',\n",
              " 'on',\n",
              " 'your',\n",
              " 'plate',\n",
              " 'do',\n",
              " 'you',\n",
              " 'want',\n",
              " 'what',\n",
              " 'you',\n",
              " 've',\n",
              " 'been',\n",
              " 'fed',\n",
              " 'are',\n",
              " 'you',\n",
              " 'the',\n",
              " 'fish',\n",
              " 'or',\n",
              " 'bait']"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_ingles = get_vocab(corpus_ingles)\n",
        "vocab_ingles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvWMUQq5zPP8"
      },
      "source": [
        "Resultado esperado:\n",
        "```\n",
        "['fed', 'been', 'or', 'want', 'plate', 'the', 've', 'your', 's', 'you', 'what', 'Are', 'bait', 'What', 'fish', 'that', 'sitting', 'Do', 'on']\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FVjU3cAzDkw"
      },
      "source": [
        "### Pregunta 2.b (0.5 puntos)\n",
        "Ahora dise√±e reglas que usted estime convenientes tanto de **Stemming** como de **Stopwords**. Implemente una funci√≥n que reciba una lista con los elementos del vocabulario, le aplique sus reglas y devuelva el vocabulario preprocesado. Explique las reglas de stemming y elecci√≥n de stopwords:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZSeU-rDYbI1"
      },
      "source": [
        "    Explique sus reglas aqu√≠:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aqu√≠ las dos reglas funcionan de la siguiente manera. Primero que todo, se usa la [documentaci√≥n para Stemming](https://spotintelligence.com/2022/12/14/stemming-python/#1_NLTK_stemming) usando la funci√≥n Stemmer (que en realidad lo que hace es tomar la ra√≠z de cada palabra), mientras que para la regla de stopping words se usa [la librer√≠a stopwords](https://pythonspot.com/nltk-stop-words/) que contiene una lista de stopwords en ingl√©s o en espa√±ol dependiendo del idioma que uno le d√©. Adem√°s, dicha funci√≥n la aplicamos como filtro en la misma definici√≥n del string que queremos que la funci√≥n pre_processing nos devuelva. Este filtro es de la siguiente manera: considera todas las palabras cuyas ra√≠ces est√°n en la instancia inicializada Stemmer, y a la vez que no est√°n en el conjunto de palabras que est√°n en stop_words. Adem√°s, dicha funci√≥n que implementamos incluye una transformaci√≥n de las palabras en espa√±ol para los strings de los idiomas, a ingl√©s, porque la funci√≥n stopwords recibe strings en ingl√©s. Algo a tener en cuenta es el hecho de que el stemming se aplica a la ra√≠z de las palabras, y en cambio el quitar las stopwords se aplica sobre las palabras completas. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "777xbIG2sqy5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/diegoespinoza/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/diegoespinoza/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "def pre_processing(vocabulario, idioma):\n",
        "    \"\"\"como podemos ver, la funci√≥n recibe un vocabulario en un idioma\n",
        "    determinado, lo que implica que debemos hacer que la funcion \n",
        "    identifique ese cambio.\"\"\"\n",
        "    if idioma == \"espanol\":\n",
        "        idioma = \"spanish\"\n",
        "    elif idioma == \"ingles\":\n",
        "        idioma = \"english\"\n",
        "    stemmer = PorterStemmer()\n",
        "    \n",
        "    stop_words = set(stopwords.words(idioma))\n",
        "    palabras = get_vocab(vocabulario)\n",
        "\n",
        "    \"\"\"ahora se ve que las palabras que est√°n en \"palabras\" sean tales que \n",
        "    no incluyan n√∫meros, caracteres especiales o espacios (mediante la condici√≥n if palabra.isalpha())\n",
        "    y que dichas palabras adem√°s no sean stopwords. Adem√°s, stemmer.stem(palabra) es una funci√≥n que \n",
        "    reduce cada palabra a su ra√≠z en dicho idioma. Aqu√≠ en un solo filtro aplicamos primero\n",
        "    stemming y luego quitamos todas las palabras que son stopwords.\"\"\"\n",
        "    palabras_procesadas = [stemmer.stem(palabra) for palabra in palabras if palabra.isalpha() and palabra not in stop_words]\n",
        "    return palabras_procesadas\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT1Rr0das2Nb",
        "outputId": "503fd5f8-ee46-4367-bee1-f85fb24cea03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulario procesado en espa√±ol: ['qui√©n', 'quier', 'quiera', 'creo', 'quiero', 'dime', 'debo', 'cantar', 's√©', 'sabe', 'mejor'] \n",
            "\n",
            "Vocabulario procesado en ingl√©s: ['sit', 'plate', 'want', 'fed', 'fish', 'bait'] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Aplicar preprocesamiento a los vocabularios de ejemplo con NLTK\n",
        "vocab_procesado_espanol = pre_processing(vocab_espanol, 'espanol')\n",
        "vocab_procesado_ingles = pre_processing(vocab_ingles, 'ingles')\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"Vocabulario procesado en espa√±ol:\", vocab_procesado_espanol, \"\\n\")\n",
        "print(\"Vocabulario procesado en ingl√©s:\", vocab_procesado_ingles, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ajmn1HaNhZE9"
      },
      "source": [
        "## P3. Bag of Words (0.5 puntos)\n",
        "Considere el siguiente corpus, donde cada elemento del arreglo representa un documento:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "vT0XQM2Ghlvy"
      },
      "outputs": [],
      "source": [
        "d0 = 'El p√°jaro come semillas'\n",
        "d1 = 'El p√°jaro se despierta y canta'\n",
        "d2 = 'El p√°jaro canta y come semillas'\n",
        "d3 = 'El pez come y nada en el agua'\n",
        "d4 = 'El pez empieza a nadar'\n",
        "d5 = 'El pez come alimento'\n",
        "corpus = [d0, d1, d2, d3, d4, d5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeOOz1Su2ATf"
      },
      "source": [
        "El objetivo da las siguientes secciones es determinar cu√°les de  los documentos entregados son los m√°s similares entre s√≠. Para ello utilizaremos la t√©cnica **TF-IDF**.\n",
        "\n",
        "Como los algoritmos de Machine Learning no comprenden el texto en lenguaje natural, estos documentos deben ser convertidos a vectores num√©ricos. La representaci√≥n m√°s simple vista en clases es la de **Bag of Words**, m√©todo mediante el cual se cuentan las apariciones de cada palabra en cada uno de los documentos entregados.\n",
        "\n",
        "Implemente la funci√≥n **`bag_of_words()`**, que recibe como input un arreglo de documentos y devuelve un dataframe de pandas con la representaci√≥n Bag of Words de los documentos entregados. En esta representaci√≥n las columnas son el vocabulario y las filas representan las apariciones de cada una de las palabras en los documentos. En otras palabras, cada fila representa el BoW de un documento.\n",
        "\n",
        "***Disclaimer: el orden de los resultados pueden variar.***\n",
        "\n",
        "\n",
        "Por ejemplo para el siguiente corpus:\n",
        "\n",
        "```\n",
        "corpus = ['El perro ladra', 'El perro come']\n",
        "```\n",
        "\n",
        "Debiese entregarnos lo siguiente:\n",
        "\n",
        "\n",
        "|   | el | perro | ladra | come |\n",
        "|---|----|-------|------|-------|\n",
        "| 0 | 1  | 1     | 1    | 0     |\n",
        "| 1 | 1  | 1     | 0    | 1     |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "_njmcRPM2GpV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MENCbDO8s_ls"
      },
      "source": [
        "Implementar funci√≥n `bag_of_words()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuaci√≥n definiremos un diccionario para poder ir guardando las palabras en el orden en el que aparecen, lo cual nos importa principalmente porque preserva dicho orden. El mismo, para una frase como: [\"el perro corre\", \"el gato salta\"] devolver√°:\n",
        "```python\n",
        "vocabulario_dict = {\n",
        "    'el': None,\n",
        "    'perro': None,\n",
        "    'corre': None}\n",
        "y si luego hago lo mismo pero con la otra parte del corpus:\n",
        "```python\n",
        "vocabulario_dict = {\n",
        "    'el': None,\n",
        "    'perro': None,\n",
        "    'corre': None,\n",
        "    'gato': None,\n",
        "    'salta': None\n",
        "}\n",
        "por lo tanto podemos decir que la parte del None no nos importa o es irrelevante porque no nos importa la llave sino el valor. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "\n",
        "def obtener_tokens(frase):\n",
        "    \"\"\"\n",
        "    Funci√≥n auxiliar para tokenizar una frase en espa√±ol.\n",
        "    \n",
        "    Input:\n",
        "        frase (str): Una oraci√≥n en espa√±ol.\n",
        "        \n",
        "    Output:\n",
        "        list: Lista de palabras en min√∫scula y sin signos de puntuaci√≥n.\n",
        "    \"\"\"\n",
        "    return [t.lower() for t in wordpunct_tokenize(frase) if t.isalpha()]\n",
        "\n",
        "\n",
        "def bag_of_words(corpus):\n",
        "    \"\"\"\n",
        "    Construye una representaci√≥n binaria de bolsa de palabras para un corpus de oraciones en espa√±ol.\n",
        "\n",
        "    1. Extrae todas las palabras √∫nicas (vocabulario) del corpus.\n",
        "       - Se usa un diccionario para preservar el orden de aparici√≥n.\n",
        "       \n",
        "    2. Construye un vector binario para cada oraci√≥n.\n",
        "       - Cada vector tiene 1 si la palabra est√° presente en la oraci√≥n, 0 si no.\n",
        "\n",
        "    Input:\n",
        "        corpus (list of str): Lista de oraciones.\n",
        "    \n",
        "    Output:\n",
        "        DataFrame: Matriz binaria con palabras como columnas y oraciones como filas.\n",
        "    \"\"\"\n",
        "    vocabulario_dict = {}\n",
        "    for frase in corpus:\n",
        "        tokens = obtener_tokens(frase)\n",
        "        for token in tokens:\n",
        "            if token not in vocabulario_dict:\n",
        "                vocabulario_dict[token] = None\n",
        "\n",
        "    vocabulario = list(vocabulario_dict.keys())\n",
        "    indice_vocab = {palabra: idx for idx, palabra in enumerate(vocabulario)}\n",
        "\n",
        "    matrix = []\n",
        "    for frase in corpus:\n",
        "        tokens_unicos = set(obtener_tokens(frase))\n",
        "        vector = [0] * len(vocabulario)\n",
        "        for token in tokens_unicos:\n",
        "            if token in indice_vocab:\n",
        "                vector[indice_vocab[token]] = 1\n",
        "        matrix.append(vector)\n",
        "\n",
        "    bag_of_words_df = pd.DataFrame(matrix, columns=vocabulario)\n",
        "    return bag_of_words_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "jWZyXGra2FOw",
        "outputId": "1b5d13ff-96c7-49c9-e400-c12441976874"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>el</th>\n",
              "      <th>p√°jaro</th>\n",
              "      <th>come</th>\n",
              "      <th>semillas</th>\n",
              "      <th>se</th>\n",
              "      <th>despierta</th>\n",
              "      <th>y</th>\n",
              "      <th>canta</th>\n",
              "      <th>pez</th>\n",
              "      <th>nada</th>\n",
              "      <th>en</th>\n",
              "      <th>agua</th>\n",
              "      <th>empieza</th>\n",
              "      <th>a</th>\n",
              "      <th>nadar</th>\n",
              "      <th>alimento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   el  p√°jaro  come  semillas  se  despierta  y  canta  pez  nada  en  agua  \\\n",
              "0   1       1     1         1   0          0  0      0    0     0   0     0   \n",
              "1   1       1     0         0   1          1  1      1    0     0   0     0   \n",
              "2   1       1     1         1   0          0  1      1    0     0   0     0   \n",
              "3   1       0     1         0   0          0  1      0    1     1   1     1   \n",
              "4   1       0     0         0   0          0  0      0    1     0   0     0   \n",
              "5   1       0     1         0   0          0  0      0    1     0   0     0   \n",
              "\n",
              "   empieza  a  nadar  alimento  \n",
              "0        0  0      0         0  \n",
              "1        0  0      0         0  \n",
              "2        0  0      0         0  \n",
              "3        0  0      0         0  \n",
              "4        1  1      1         0  \n",
              "5        0  0      0         1  "
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_bow = bag_of_words(corpus)\n",
        "dataset_bow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qEA2Ic2sLlh"
      },
      "source": [
        "Soluci√≥n esperada:\n",
        "\n",
        "|    |   El |   p√°jaro |   despierta |   el |   come |   a |   nadar |   se |   en |   y |   alimento |   semillas |   pez |   empieza |   canta |   agua |   nada |\n",
        "|:---|-----:|---------:|------------:|-----:|-------:|----:|--------:|-----:|-----:|----:|-----------:|-----------:|------:|----------:|--------:|-------:|-------:|\n",
        "| d0 |    1 |        1 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   0 |          0 |          1 |     0 |         0 |       0 |      0 |      0 |\n",
        "| d1 |    1 |        1 |           1 |    0 |      0 |   0 |       0 |    1 |    0 |   1 |          0 |          0 |     0 |         0 |       1 |      0 |      0 |\n",
        "| d2 |    1 |        1 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   1 |          0 |          1 |     0 |         0 |       1 |      0 |      0 |\n",
        "| d3 |    1 |        0 |           0 |    1 |      1 |   0 |       0 |    0 |    1 |   1 |          0 |          0 |     1 |         0 |       0 |      1 |      1 |\n",
        "| d4 |    1 |        0 |           0 |    0 |      0 |   1 |       1 |    0 |    0 |   0 |          0 |          0 |     1 |         1 |       0 |      0 |      0 |\n",
        "| d5 |    1 |        0 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   0 |          1 |          0 |     1 |         0 |       0 |      0 |      0 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMv3UZdRhgqT"
      },
      "source": [
        "## P4. TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oxW5CZjhoE9"
      },
      "source": [
        "### 4.a TF (0.25 puntos)\n",
        "\n",
        "Ahora debemos usar el dataframe del ejercicio anterior para calcular la matriz de TF normalizada por la m√°xima frecuencia $\\max_i({\\text{tf}_{i,j}})$, donde\n",
        "$i$ corresponde al √≠ndice de las filas (BoW) y $j$ al de las columnas (palabras). Es decir, dividir cada BoW sobre la cantidad de veces de la palabra que aparezca m√°s veces en ese vector.\n",
        "\n",
        "\n",
        "$$\\text{nft}_{i,j} = \\frac{\\text{tf}_{i,j}}{\\max_i({\\text{tf}_{i,j})}}$$\n",
        "\n",
        "Implemente la funci√≥n `calc_tf(dataset_bow)`, que entrega la matriz de TF normalizada del BoW del dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "qQhnJuuShmR5"
      },
      "outputs": [],
      "source": [
        "def calc_tf(dataset_bow):\n",
        "    ### Aqu√≠ inicia tu c√≥digo ###\n",
        "    pass\n",
        "    ### Aqu√≠ termina tu c√≥digo ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "urDKFQVu2p3V",
        "outputId": "e26338b6-05e9-423f-afca-9fc621ebccd3"
      },
      "outputs": [],
      "source": [
        "tf = calc_tf(dataset_bow)\n",
        "tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Swo3ZjwVtZlq"
      },
      "source": [
        "Soluci√≥n esperada:\n",
        "\n",
        "|    |   El |   p√°jaro |   despierta |   el |   come |   a |   nadar |   se |   en |   y |   alimento |   semillas |   pez |   empieza |   canta |   agua |   nada |\n",
        "|:---|-----:|---------:|------------:|-----:|-------:|----:|--------:|-----:|-----:|----:|-----------:|-----------:|------:|----------:|--------:|-------:|-------:|\n",
        "| d0 |    1 |        1 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   0 |          0 |          1 |     0 |         0 |       0 |      0 |      0 |\n",
        "| d1 |    1 |        1 |           1 |    0 |      0 |   0 |       0 |    1 |    0 |   1 |          0 |          0 |     0 |         0 |       1 |      0 |      0 |\n",
        "| d2 |    1 |        1 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   1 |          0 |          1 |     0 |         0 |       1 |      0 |      0 |\n",
        "| d3 |    1 |        0 |           0 |    1 |      1 |   0 |       0 |    0 |    1 |   1 |          0 |          0 |     1 |         0 |       0 |      1 |      1 |\n",
        "| d4 |    1 |        0 |           0 |    0 |      0 |   1 |       1 |    0 |    0 |   0 |          0 |          0 |     1 |         1 |       0 |      0 |      0 |\n",
        "| d5 |    1 |        0 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   0 |          1 |          0 |     1 |         0 |       0 |      0 |      0 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh2bFyHFhpbM"
      },
      "source": [
        "### 4.b IDF (0.5 puntos)\n",
        "\n",
        "Implementar `calc_idf(dataset_bow)`. √âsta debe retornar un diccionario en donde las llaves sean las palabras y los valores sean el c√°lculo de cada idf por palabra.\n",
        "\n",
        "Recordar que $\\text{idf}_{t_i} = \\log_{10}\\frac{N}{n_i}$ con $N = $ n√∫mero de documentos y $n_i = $ n√∫mero de documentos que contienen la palabra $t_i$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "tGLjlSY02usu"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "qoU4AIrm2sDT"
      },
      "outputs": [],
      "source": [
        "def calc_idf(dataset_bow):\n",
        "    ### Aqu√≠ inicia tu c√≥digo ###\n",
        "    pass\n",
        "    ### Aqu√≠ termina tu c√≥digo ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXPErPdw2uQx",
        "outputId": "6f4076e5-79e5-4d21-d233-913c3a47adab"
      },
      "outputs": [],
      "source": [
        "idf = calc_idf(dataset_bow)\n",
        "idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmp5lXdquAD1"
      },
      "source": [
        "Soluci√≥n esperada:\n",
        "```\n",
        "{'El': 0.0,\n",
        " 'p√°jaro': 0.3010299956639812,\n",
        " 'despierta': 0.7781512503836436,\n",
        " 'el': 0.7781512503836436,\n",
        " 'come': 0.17609125905568124,\n",
        " 'a': 0.7781512503836436,\n",
        " 'nadar': 0.7781512503836436,\n",
        " 'se': 0.7781512503836436,\n",
        " 'en': 0.7781512503836436,\n",
        " 'y': 0.3010299956639812,\n",
        " 'alimento': 0.7781512503836436,\n",
        " 'semillas': 0.47712125471966244,\n",
        " 'pez': 0.3010299956639812,\n",
        " 'empieza': 0.7781512503836436,\n",
        " 'canta': 0.47712125471966244,\n",
        " 'agua': 0.7781512503836436,\n",
        " 'nada': 0.7781512503836436}\n",
        " ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC-_vwiV20XL"
      },
      "source": [
        "### 4.c TF-IDF (0.25 puntos)\n",
        "Programe la funci√≥n `calc_tf_idf(tf, idf)` que entrega el dataframe TF-IDF asociado al dataset que estamos analizando."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "004IuUyt23_6"
      },
      "outputs": [],
      "source": [
        "def calc_tf_idf(tf, idf):\n",
        "    ### Aqu√≠ inicia tu c√≥digo ###\n",
        "    pass\n",
        "    ### Aqu√≠ termina tu c√≥digo ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "KXjP0S3626dw",
        "outputId": "34863c23-c513-4556-d500-5a8e0141d8f8"
      },
      "outputs": [],
      "source": [
        "tf_idf = calc_tf_idf(tf, idf)\n",
        "tf_idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNTa32IsuLWl"
      },
      "source": [
        "Soluci√≥n esperada:\n",
        "\n",
        "|    |   El |   p√°jaro |   despierta |       el |     come |        a |    nadar |       se |       en |       y |   alimento |   semillas |     pez |   empieza |    canta |     agua |     nada |\n",
        "|:---|-----:|---------:|------------:|---------:|---------:|---------:|---------:|---------:|---------:|--------:|-----------:|-----------:|--------:|----------:|---------:|---------:|---------:|\n",
        "| d0 |    0 |  0.30103 |    0        | 0        | 0.176091 | 0        | 0        | 0        | 0        | 0       |   0        |   0.477121 | 0       |  0        | 0        | 0        | 0        |\n",
        "| d1 |    0 |  0.30103 |    0.778151 | 0        | 0        | 0        | 0        | 0.778151 | 0        | 0.30103 |   0        |   0        | 0       |  0        | 0.477121 | 0        | 0        |\n",
        "| d2 |    0 |  0.30103 |    0        | 0        | 0.176091 | 0        | 0        | 0        | 0        | 0.30103 |   0        |   0.477121 | 0       |  0        | 0.477121 | 0        | 0        |\n",
        "| d3 |    0 |  0       |    0        | 0.778151 | 0.176091 | 0        | 0        | 0        | 0.778151 | 0.30103 |   0        |   0        | 0.30103 |  0        | 0        | 0.778151 | 0.778151 |\n",
        "| d4 |    0 |  0       |    0        | 0        | 0        | 0.778151 | 0.778151 | 0        | 0        | 0       |   0        |   0        | 0.30103 |  0.778151 | 0        | 0        | 0        |\n",
        "| d5 |    0 |  0       |    0        | 0        | 0.176091 | 0        | 0        | 0        | 0        | 0       |   0.778151 |   0        | 0.30103 |  0        | 0        | 0        | 0        |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8sQEjVshjQ7"
      },
      "source": [
        "## P5. Cosine-similarity (0.25 puntos)\n",
        "Ahora que tenemos el dataframe de TF-IDF, nos queda calcular la similitud coseno entre todos los vectores. Notar que la matriz resultante ser√° una matriz sim√©trica.\n",
        "\n",
        "Implemente la funci√≥n *cosine_similarity(v1, v2)* que recibe dos vectores (v1 y v2) y calcula la similitud coseno entre ambos. Concluya cu√°les son los dos documentos m√°s similares."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "_68mo-BLhmuV"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(v1, v2):\n",
        "    ### Aqu√≠ inicia tu c√≥digo ###\n",
        "    pass\n",
        "    ### Aqu√≠ termina tu c√≥digo ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5z-23CN2_lU",
        "outputId": "6798f54e-69dc-40c6-ca35-d2d4995fe168"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'index'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[54], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m similarity_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, v1 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtf_idf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[1;32m      3\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m j, v2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tf_idf\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[1;32m      4\u001b[0m       similarity \u001b[38;5;241m=\u001b[39m cosine_similarity(tf_idf\u001b[38;5;241m.\u001b[39mloc[v1]\u001b[38;5;241m.\u001b[39mvalues, tf_idf\u001b[38;5;241m.\u001b[39mloc[v2]\u001b[38;5;241m.\u001b[39mvalues)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'index'"
          ]
        }
      ],
      "source": [
        "similarity_matrix = np.zeros((6,6))\n",
        "for i, v1 in enumerate(tf_idf.index.values):\n",
        "  for j, v2 in enumerate(tf_idf.index.values):\n",
        "      similarity = cosine_similarity(tf_idf.loc[v1].values, tf_idf.loc[v2].values)\n",
        "      similarity_matrix[i][j] = similarity\n",
        "\n",
        "for i in range(6):\n",
        "  mask = [k != i for k in range(6)]\n",
        "  j = np.argmax(similarity_matrix[i][mask])\n",
        "\n",
        "  print(corpus[i])\n",
        "  print(\"> Mas similar:\", np.array(corpus)[mask][j])\n",
        "  print(\"> Similitud:\", similarity_matrix[i][mask][j], \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71oH4JHXulGQ"
      },
      "source": [
        "Soluci√≥n esperada:\n",
        "```\n",
        "El p√°jaro come semillas\n",
        "> Mas similar: El p√°jaro canta y come semillas\n",
        "> Similitud: 0.7233435041520414\n",
        "\n",
        "El p√°jaro se despierta y canta\n",
        "> Mas similar: El p√°jaro canta y come semillas\n",
        "> Similitud: 0.39320101823128945\n",
        "\n",
        "El p√°jaro canta y come semillas\n",
        "> Mas similar: El p√°jaro come semillas\n",
        "> Similitud: 0.7233435041520414\n",
        "\n",
        "El pez come y nada en el agua\n",
        "> Mas similar: El p√°jaro canta y come semillas\n",
        "> Similitud: 0.09171890791406168\n",
        "\n",
        "El pez empieza a nadar\n",
        "> Mas similar: El pez come alimento\n",
        "> Similitud: 0.07695078406752713\n",
        "\n",
        "El pez come alimento\n",
        "> Mas similar: El pez come y nada en el agua\n",
        "> Similitud: 0.0878790037217323\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDZln45jfjMf"
      },
      "source": [
        "## P6 N-gramas (0.75 punto)\n",
        "\n",
        "En esta secci√≥n debera determinar los n-gramas del la cancion \"Oh algoritmo\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7duKoBvlSgg"
      },
      "source": [
        "### 6.a Corpus de entrenamiento y test (0.25 puntos)\n",
        "\n",
        "En esta subsecci√≥n debera definir el conjunto de entrenamiento y test de un corpus. Eliga una particion del 80% y 20% del texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juDVurFfl3eZ",
        "outputId": "4c6398a1-ed7b-45ed-cdf7-c5fcd6ffb4c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Letra de \"¬°Oh, Algoritmo!\" ft. Nora Erez]\n",
            "\n",
            "[Refr√°n: Jorge Drexler]\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "\n",
            "[Estribillo: Jorge Drexler]\n",
            "Dime qu√© debo cantar\n",
            "Oh, algoritmo\n",
            "S√© que lo sabes mejor\n",
            "Incluso que yo mismo\n",
            "\n",
            "[Verso 1: Nora Erez]\n",
            "Wait, what's that money that you spent?\n",
            "What's that sitting on your plate?\n",
            "Do you want what you've been fed?\n",
            "Are you the fish or bait?\n",
            "Mmm, I'm on the top of the roof and I feel like a jail\n",
            "Rather not pay the bail\n",
            "To dangerous people with blood on their faces\n",
            "So I'm sharing a cell with the masses\n",
            "The underground always strive for the main\n",
            "Streaming like Grande's big-ass ring\n",
            "Screaming: I'll write you out my will\n",
            "Conscious is free, but not the will\n",
            "Conscious is free, but not the will\n",
            "You might also like\n",
            "Amor al Arte\n",
            "Jorge Drexler\n",
            "Tinta y Tiempo\n",
            "Jorge Drexler\n",
            "Asilo\n",
            "Jorge Drexler\n",
            "[Pre-Estribillo: Nora Erez]\n",
            "So if you want me to want what I believe that I want\n",
            "Can I choose to quit?\n",
            "\n",
            "[Estribillo: Jorge Drexler]\n",
            "Dime qu√© debo cantar\n",
            "Oh, algoritmo\n",
            "S√© que lo sabes mejor\n",
            "Incluso que yo mismo\n",
            "\n",
            "[Verso 2: Jorge Drexler]\n",
            "Por ejemplo, esta canci√≥n\n",
            "¬øQu√© algoritmo la pari√≥?\n",
            "Me pregunto si fui yo\n",
            "¬øLa elegiste o te eligi√≥?\n",
            "\n",
            "[Verso 3: Jorge Drexler]\n",
            "Dios era la letra chica al final del papel\n",
            "Ya no contamos con √âl\n",
            "Fin de la Luna de miel\n",
            "Y el libre albedr√≠o es un cauce vac√≠o\n",
            "Un barco que no tiene r√≠o\n",
            "Ni timonel\n",
            "\n",
            "[Verso 4: Jorge Drexler]\n",
            "Todos aplauden, t√∫ tambi√©n\n",
            "Pero no queda claro qui√©n\n",
            "Tiene del mango a la sart√©n\n",
            "Del sacrificio\n",
            "Piel o silicio\n",
            "Y el precipicio\n",
            "Dice: Ven, ven, ven\n",
            "[Refr√°n: Jorge Drexler]\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Dime qu√© debo cantar)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Oh, algoritmo)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(S√© que lo sabes mejor)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Incluso que yo mismo)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Dime qu√© debo cantar)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Oh, algoritmo)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(S√© que lo sabes mejor)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Incluso que yo mismo)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Wow)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # Abre el archivo en modo lectura (\"r\")\n",
        "    with open(\"oh_algoritmo.txt\", \"r\") as archivo:\n",
        "        # Lee el contenido del archivo\n",
        "        texto = archivo.read()\n",
        "        # Imprime el contenido\n",
        "        print(texto)\n",
        "except FileNotFoundError:\n",
        "    print(\"El archivo no se encuentra.\")\n",
        "except Exception as e:\n",
        "    print(\"Ocurri√≥ un error:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYCw0AqOmlzD"
      },
      "source": [
        "Defina una funcion `get_sentences()` que entregue todas las oraciones del corpus que contengan al menos una palabra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C88f9aVil9d_"
      },
      "outputs": [],
      "source": [
        "def get_sentences(texto):\n",
        "  ## Implementar aqu√≠\n",
        "  pass\n",
        "  ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbZ8EhgHmR2c",
        "outputId": "c4b6502e-889a-4339-ee58-1b427867c405"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[Letra de \"¬°Oh, Algoritmo!\" ft. Nora Erez]',\n",
              " '[Refr√°n: Jorge Drexler]',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '[Estribillo: Jorge Drexler]',\n",
              " 'Dime qu√© debo cantar',\n",
              " 'Oh, algoritmo',\n",
              " 'S√© que lo sabes mejor',\n",
              " 'Incluso que yo mismo',\n",
              " '[Verso 1: Nora Erez]',\n",
              " \"Wait, what's that money that you spent?\",\n",
              " \"What's that sitting on your plate?\",\n",
              " \"Do you want what you've been fed?\",\n",
              " 'Are you the fish or bait?',\n",
              " \"Mmm, I'm on the top of the roof and I feel like a jail\",\n",
              " 'Rather not pay the bail',\n",
              " 'To dangerous people with blood on their faces',\n",
              " \"So I'm sharing a cell with the masses\",\n",
              " 'The underground always strive for the main',\n",
              " \"Streaming like Grande's big-ass ring\",\n",
              " \"Screaming: I'll write you out my will\",\n",
              " 'Conscious is free, but not the will',\n",
              " 'Conscious is free, but not the will',\n",
              " 'You might also like',\n",
              " 'Amor al Arte',\n",
              " 'Jorge Drexler',\n",
              " 'Tinta y Tiempo',\n",
              " 'Jorge Drexler',\n",
              " 'Asilo',\n",
              " 'Jorge Drexler',\n",
              " '[Pre-Estribillo: Nora Erez]',\n",
              " 'So if you want me to want what I believe that I want',\n",
              " 'Can I choose to quit?',\n",
              " '[Estribillo: Jorge Drexler]',\n",
              " 'Dime qu√© debo cantar',\n",
              " 'Oh, algoritmo',\n",
              " 'S√© que lo sabes mejor',\n",
              " 'Incluso que yo mismo',\n",
              " '[Verso 2: Jorge Drexler]',\n",
              " 'Por ejemplo, esta canci√≥n',\n",
              " '¬øQu√© algoritmo la pari√≥?',\n",
              " 'Me pregunto si fui yo',\n",
              " '¬øLa elegiste o te eligi√≥?',\n",
              " '[Verso 3: Jorge Drexler]',\n",
              " 'Dios era la letra chica al final del papel',\n",
              " 'Ya no contamos con √âl',\n",
              " 'Fin de la Luna de miel',\n",
              " 'Y el libre albedr√≠o es un cauce vac√≠o',\n",
              " 'Un barco que no tiene r√≠o',\n",
              " 'Ni timonel',\n",
              " '[Verso 4: Jorge Drexler]',\n",
              " 'Todos aplauden, t√∫ tambi√©n',\n",
              " 'Pero no queda claro qui√©n',\n",
              " 'Tiene del mango a la sart√©n',\n",
              " 'Del sacrificio',\n",
              " 'Piel o silicio',\n",
              " 'Y el precipicio',\n",
              " 'Dice: Ven, ven, ven',\n",
              " '[Refr√°n: Jorge Drexler]',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Dime qu√© debo cantar)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Oh, algoritmo)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(S√© que lo sabes mejor)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Incluso que yo mismo)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Dime qu√© debo cantar)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Oh, algoritmo)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(S√© que lo sabes mejor)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Incluso que yo mismo)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Wow)']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "oraciones_limpias = get_sentences(texto)\n",
        "oraciones_limpias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEBzcR6Ym0Us"
      },
      "source": [
        "Deber√≠a obtener en total 87 oraciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pDN1vGEmwRQ",
        "outputId": "bdecd9e4-4d9e-4297-9319-8f938fc726ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "87"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(oraciones_limpias) == 87"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp9dq8omm7cD"
      },
      "source": [
        "Ahora definiremos el conjunto de entrenamiento y prueba para las oraciones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVHoR_-inEK1",
        "outputId": "c28b779e-ab7e-4c55-b061-86701fadacba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(69, 18)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split = int(len(oraciones_limpias) * 0.8)\n",
        "train_corpus = oraciones_limpias[:split]\n",
        "test_corpus = oraciones_limpias[split:]\n",
        "\n",
        "len(train_corpus), len(test_corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csdw0qNsmjTF"
      },
      "source": [
        "### 6.b Estimaci√≥n de N-gramas (0.5 puntos)\n",
        "\n",
        "Defina una funci√≥n que reciba una lista de oraciones de un corpus y un N que indique el tama√±o de los N-gramas. La funci√≥n debe retornar un diccionario de Python donde la llave es un token (o palabra) y el valor es la cantidad de veces que ocurre el token, es decir, la frecuencia. En el caso de N-gramas con N mayor a 1 (como bi-gramas o tri-gramas) debe a√±adir un token especial al inicio o final de cada oraci√≥n seg√∫n corresponda (ver clases del curso)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bB2_1y1etIBF"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lbrl3WVnmRzj"
      },
      "outputs": [],
      "source": [
        "def n_grams(corpus, n=3):\n",
        "  ## Implementar aqu√≠\n",
        "  pass\n",
        "  ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAoYncsp3C7u"
      },
      "outputs": [],
      "source": [
        "n_grams(train_corpus, n=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8XDEuRF3Grx"
      },
      "outputs": [],
      "source": [
        "n_grams(train_corpus, n=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCpbhiXp3Gpg"
      },
      "outputs": [],
      "source": [
        "n_grams(train_corpus, n=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHgEpVPj21fs"
      },
      "source": [
        "Debe mostrar que su m√©todo funciona para $N = 1,2,3$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMzLfBLBk-i7"
      },
      "source": [
        "## P7. Perplexity (1 punto)\n",
        "\n",
        "En esta secci√≥n evaluar√°n su modelo de n-gramas y determinar√°n la probabilidad de oraciones y la perplejidad con un conjunto de test. Recuerde que la perplejidad se define de la siguiente manera:\n",
        "\n",
        "$$\n",
        "\\text{Perplexity} = 2^{-l} \\quad \\quad l = \\frac{1}{M} \\sum_{i=1}^{m} \\log p(s_i)\n",
        "$$\n",
        "\n",
        "con $m$ el n√∫mero de oraciones del corpus y $M$ el tama√±o del vocabulario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tas4KYhZ28_C"
      },
      "source": [
        "### 7.a Obtener probabilidades (0.5 puntos)\n",
        "\n",
        "En esta secci√≥n implementar√° una funci√≥n que determine la probabilidad de una oraci√≥n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYH0ScM44Jrb"
      },
      "source": [
        "Defina una funci√≥n que reciba una oraci√≥n, un diccionario con n-gramas y el valor de $n$. La funci√≥n debe entregar la probabilidad de cualquier oraci√≥n.\n",
        "\n",
        "**Hint**: No olvide los posibles casos borde, como palabras fuera del vocabulario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWGsq22H4Sxz"
      },
      "outputs": [],
      "source": [
        "def get_probability(sentence, n_grams_frequency, n):\n",
        "  ## Implementar aqu√≠\n",
        "  pass\n",
        "  ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1UkfOz75W_P"
      },
      "source": [
        "Pruebe su funci√≥n con oraciones frecuentes y comente sus resultados\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ITfzYJx5fqV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfnIFV7F3eOL"
      },
      "source": [
        "### 7.b Perplexity en conjunto de test (0.5 puntos)\n",
        "\n",
        "En esta sub-secci√≥n deber√° calcular la perplejidad del corpus de test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N21I_mPl5Cqx"
      },
      "source": [
        "Defina una funci√≥n que reciba un corpus de test y retorne la perplexity (ver clases del curso). Utilice la funci√≥n de la secci√≥n anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VC4Vbk3q5LsY"
      },
      "outputs": [],
      "source": [
        "def get_perplexity(corpus, n):\n",
        "  ## implementar aqu√≠\n",
        "  pass\n",
        "  ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAjpRDoG5sUJ"
      },
      "outputs": [],
      "source": [
        "get_perplexity(test_corpus, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhc07wXM5gyI"
      },
      "source": [
        "D√© una interpretacion de la perplexity en el corpus de test:\n",
        "```\n",
        "Nosotros ...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYNsmR4OPQQX"
      },
      "source": [
        "## P8. Interpolaci√≥n Lineal (0.5 puntos)\n",
        "\n",
        "Cree una funci√≥n que obtenga la probabilidad de una oraci√≥n interpolando linealmente modelos de unigrama, bigrama y trigrama ponderados por $\\lambda_1, \\lambda_2$ y $\\lambda_3$ respectivamente. Para esto use las funciones que cre√≥ anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7kcWusAPPv5"
      },
      "outputs": [],
      "source": [
        "def get_probability_lineal_interpol(sentence, corpus, l_1, l_2, l_3):\n",
        "  ## Implementar aqu√≠\n",
        "  pass\n",
        "  ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO1J_E77RQp3"
      },
      "source": [
        "Defina una funci√≥n para calcular la perplejidad de un corpus con interpolaci√≥n lineal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAS94E1UROkg"
      },
      "outputs": [],
      "source": [
        "def get_pp_interpol(corpus, l_1, l_2, l_3):\n",
        "  ## Implementar aqu√≠\n",
        "  pass\n",
        "  ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqoX9_o2SHOY"
      },
      "source": [
        "Ahora haga pruebas con distintos valores de $\\lambda_1, \\lambda_2$ y $\\lambda_3$, incluyendo valores extremos (por ejemplo $[1, 0, 0]$). Comente sus resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZ6-NA3AOUmq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
