{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiegoEspinozaoss/Natural_Language_Processing_CC6205-1/blob/main/Tarea_1_IR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxrkZWMLZB8z"
      },
      "source": [
        "# Tarea 1: Introducción, Modelos de Espacio Vectorial, Recuperación de Información y Modelos de Lenguaje\n",
        "\n",
        "**Procesamiento de Lenguaje Natural (CC6205-1 - Otoño 2025)**\n",
        "\n",
        "## Tarjeta de Identificación\n",
        "\n",
        "- **Nombre(s):** ```Diego Espinoza, Juan Miño, Emilio Torres```\n",
        "- **Fecha límite de entrega 📆:** 15 de abril de 2025\n",
        "- **Tiempo estimado de dedicación:** 4 horas\n",
        "\n",
        "---\n",
        "\n",
        "## 📌 Instrucciones\n",
        "\n",
        "¡Bienvenid@s a la primera tarea del curso de *Natural Language Processing* (NLP)!\n",
        "\n",
        "El objetivo de esta tarea es evaluar los conceptos teóricos de las primeras semanas de clases, centrándose en:\n",
        "\n",
        "- **Recuperación de Información (IR)**\n",
        "- **Modelos de Espacio Vectorial**\n",
        "- **Modelos de Lenguaje**\n",
        "\n",
        "Si aún no has revisado el contenido correspondiente, se recomienda consultar las referencias disponibles al final del documento.\n",
        "\n",
        "### 📢 Consideraciones generales\n",
        "\n",
        "✅ La tarea debe realizarse en **grupos de hasta 3 personas**.\n",
        "\n",
        "✅ La entrega debe realizarse a través de **U-Cursos**, a más tardar en la fecha estipulada. **No se aceptarán entregas atrasadas.**\n",
        "\n",
        "✅ El formato de entrega es este mismo **Jupyter Notebook**.\n",
        "\n",
        "✅ Su código será ejecutado al momento de la revisión. **Verifiquen que no tenga errores de compilación.**\n",
        "\n",
        "✅ Es obligatorio completar la **Tarjeta de Identificación**. **No se asignará nota sin ella.**\n",
        "\n",
        "---\n",
        "\n",
        "## 📚 Material de Referencia\n",
        "\n",
        "### 📄 Diapositivas del curso\n",
        "\n",
        "- [Introducción al curso](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-introduction.pdf)\n",
        "- [Modelos de Espacio Vectorial y Recuperación de Información](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-IR.pdf)\n",
        "- [Modelos Probabilísticos de Lenguaje](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-PLM.pdf)\n",
        "\n",
        "### 📺 Videos del curso\n",
        "\n",
        "- **Introducción**: [Parte 1](https://www.youtube.com/watch?v=HEKTNOttGvU) | [Parte 2](https://www.youtube.com/watch?v=P8cwnI-f-Kg)\n",
        "- **Recuperación de Información**: [Parte 1](https://www.youtube.com/watch?v=FXIVClF370w&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=3) | [Parte 2](https://www.youtube.com/watch?v=f8nG1EMmPZk&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=3)\n",
        "- **Modelos Probabilísticos de Lenguaje**: [Parte 1](https://www.youtube.com/watch?v=9E2jJ6kcb4Y&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=3) | [Parte 2](https://www.youtube.com/watch?v=ZWqbEQXLra0&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=5) | [Parte 3](https://www.youtube.com/watch?v=tsumFqwFlaA&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=6) | [Parte 4](https://www.youtube.com/watch?v=s3TWdv4sqkg&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJq)\n",
        "\n",
        "---\n",
        "\n",
        "📌 **Recuerda:** La claridad y organización en la entrega son clave para una mejor evaluación. Incluir analisis apropiado. ¡Mucho éxito! 🚀"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7w4BT1qmChV"
      },
      "source": [
        "## P1. Tokenización\n",
        "\n",
        "En el primer ejercicio veremos la dificultad de tokenizar textos no estructurados, destacando la importancia de tener librerías que realicen este trabajo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlgSZrB2oe1H",
        "outputId": "9699523d-c2e5-4dc7-a094-26caab6e8e4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ignorando conexión drive-colab\n"
          ]
        }
      ],
      "source": [
        "# En caso de desarrollar la tarea desde colab, con el siguiente código podemos cargar los archivos desde drive:\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(\"/content/drive\", force_remount=True)\n",
        "    path = '/content/drive/MyDrive/nlp/oh_algoritmo.txt'\n",
        "except:\n",
        "    print('Ignorando conexión drive-colab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCKFrnZcoy2F"
      },
      "source": [
        "Ejecute el código a continuación para cargar el ejemplo. Recuerde realizar la modificación al directorio en caso que el archivo no se encuentre en el mismo directorio del Jupyter Notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9CteGwEmDKw",
        "outputId": "4ab9ef8a-c16e-4580-f726-6d8895ad0727"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Letra de \"¡Oh, Algoritmo!\" ft. Nora Erez]\n",
            "\n",
            "[Refrán: Jorge Drexler]\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "\n",
            "[Estribillo: Jorge Drexler]\n",
            "Dime qué debo cantar\n",
            "Oh, algoritmo\n",
            "Sé que lo sabes mejor\n",
            "Incluso que yo mismo\n",
            "\n",
            "[Verso 1: Nora Erez]\n",
            "Wait, what's that money that you spent?\n",
            "What's that sitting on your plate?\n",
            "Do you want what you've been fed?\n",
            "Are you the fish or bait?\n",
            "Mmm, I'm on the top of the roof and I feel like a jail\n",
            "Rather not pay the bail\n",
            "To dangerous people with blood on their faces\n",
            "So I'm sharing a cell with the masses\n",
            "The underground always strive for the main\n",
            "Streaming like Grande's big-ass ring\n",
            "Screaming: I'll write you out my will\n",
            "Conscious is free, but not the will\n",
            "Conscious is free, but not the will\n",
            "You might also like\n",
            "Amor al Arte\n",
            "Jorge Drexler\n",
            "Tinta y Tiempo\n",
            "Jorge Drexler\n",
            "Asilo\n",
            "Jorge Drexler\n",
            "[Pre-Estribillo: Nora Erez]\n",
            "So if you want me to want what I believe that I want\n",
            "Can I choose to quit?\n",
            "\n",
            "[Estribillo: Jorge Drexler]\n",
            "Dime qué debo cantar\n",
            "Oh, algoritmo\n",
            "Sé que lo sabes mejor\n",
            "Incluso que yo mismo\n",
            "\n",
            "[Verso 2: Jorge Drexler]\n",
            "Por ejemplo, esta canción\n",
            "¿Qué algoritmo la parió?\n",
            "Me pregunto si fui yo\n",
            "¿La elegiste o te eligió?\n",
            "\n",
            "[Verso 3: Jorge Drexler]\n",
            "Dios era la letra chica al final del papel\n",
            "Ya no contamos con Él\n",
            "Fin de la Luna de miel\n",
            "Y el libre albedrío es un cauce vacío\n",
            "Un barco que no tiene río\n",
            "Ni timonel\n",
            "\n",
            "[Verso 4: Jorge Drexler]\n",
            "Todos aplauden, tú también\n",
            "Pero no queda claro quién\n",
            "Tiene del mango a la sartén\n",
            "Del sacrificio\n",
            "Piel o silicio\n",
            "Y el precipicio\n",
            "Dice: Ven, ven, ven\n",
            "[Refrán: Jorge Drexler]\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "(Dime qué debo cantar)\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "(Oh, algoritmo)\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "(Sé que lo sabes mejor)\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "(Incluso que yo mismo)\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "(Dime qué debo cantar)\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "(Oh, algoritmo)\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "(Sé que lo sabes mejor)\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "(Incluso que yo mismo)\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "(Wow)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # Abre el archivo en modo lectura (\"r\")\n",
        "    with open(\"oh_algoritmo.txt\", \"r\") as archivo:\n",
        "        # Lee el contenido del archivo\n",
        "        texto = archivo.read()\n",
        "        # Imprime el contenido\n",
        "        print(texto)\n",
        "except FileNotFoundError:\n",
        "    print(\"El archivo no se encuentra.\")\n",
        "except Exception as e:\n",
        "    print(\"Ocurrió un error:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPSSO2kJoArL"
      },
      "source": [
        "Fuente: https://genius.com/Jorge-drexler-oh-algoritmo-lyrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fG0hLbHg9dn"
      },
      "source": [
        "### Pregunta 1.a (0.25 puntos)\n",
        "\n",
        "Diseñe una función **`get_tokens()`** que reciba un texto y entregue una lista con sus tokens. Es libre de elegir la forma de tokenizar mientras no utilice librerías con tokenizadores ya implementados. Puede utilizar la librería **re** importada para trabajar símbolos. Explique su razonamiento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiRMkdjwazFT"
      },
      "outputs": [],
      "source": [
        "def get_tokens(texto):\n",
        "    \"\"\"\n",
        "    básicamente lo que hace la función es tomar un texto\n",
        "    y ver descartar todos los caracteres que no son palabras,\n",
        "    es decir, descartar toda aquello que no pueda ser expresado\n",
        "    como una serie continua de vocales o consonantes. \n",
        "    \"\"\"\n",
        "    tokens = re.findall(r'\\b\\w+\\b', texto)\n",
        "    return tokens\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "hDBZn4kOm7uH"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Letra',\n",
              " 'de',\n",
              " 'Oh',\n",
              " 'Algoritmo',\n",
              " 'ft',\n",
              " 'Nora',\n",
              " 'Erez',\n",
              " 'Refrán',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Estribillo',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Dime',\n",
              " 'qué',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " 'Oh',\n",
              " 'algoritmo',\n",
              " 'Sé',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " 'Verso',\n",
              " '1',\n",
              " 'Nora',\n",
              " 'Erez',\n",
              " 'Wait',\n",
              " 'what',\n",
              " 's',\n",
              " 'that',\n",
              " 'money',\n",
              " 'that',\n",
              " 'you',\n",
              " 'spent',\n",
              " 'What',\n",
              " 's',\n",
              " 'that',\n",
              " 'sitting',\n",
              " 'on',\n",
              " 'your',\n",
              " 'plate',\n",
              " 'Do',\n",
              " 'you',\n",
              " 'want',\n",
              " 'what',\n",
              " 'you',\n",
              " 've',\n",
              " 'been',\n",
              " 'fed',\n",
              " 'Are',\n",
              " 'you',\n",
              " 'the',\n",
              " 'fish',\n",
              " 'or',\n",
              " 'bait',\n",
              " 'Mmm',\n",
              " 'I',\n",
              " 'm',\n",
              " 'on',\n",
              " 'the',\n",
              " 'top',\n",
              " 'of',\n",
              " 'the',\n",
              " 'roof',\n",
              " 'and',\n",
              " 'I',\n",
              " 'feel',\n",
              " 'like',\n",
              " 'a',\n",
              " 'jail',\n",
              " 'Rather',\n",
              " 'not',\n",
              " 'pay',\n",
              " 'the',\n",
              " 'bail',\n",
              " 'To',\n",
              " 'dangerous',\n",
              " 'people',\n",
              " 'with',\n",
              " 'blood',\n",
              " 'on',\n",
              " 'their',\n",
              " 'faces',\n",
              " 'So',\n",
              " 'I',\n",
              " 'm',\n",
              " 'sharing',\n",
              " 'a',\n",
              " 'cell',\n",
              " 'with',\n",
              " 'the',\n",
              " 'masses',\n",
              " 'The',\n",
              " 'underground',\n",
              " 'always',\n",
              " 'strive',\n",
              " 'for',\n",
              " 'the',\n",
              " 'main',\n",
              " 'Streaming',\n",
              " 'like',\n",
              " 'Grande',\n",
              " 's',\n",
              " 'big',\n",
              " 'ass',\n",
              " 'ring',\n",
              " 'Screaming',\n",
              " 'I',\n",
              " 'll',\n",
              " 'write',\n",
              " 'you',\n",
              " 'out',\n",
              " 'my',\n",
              " 'will',\n",
              " 'Conscious',\n",
              " 'is',\n",
              " 'free',\n",
              " 'but',\n",
              " 'not',\n",
              " 'the',\n",
              " 'will',\n",
              " 'Conscious',\n",
              " 'is',\n",
              " 'free',\n",
              " 'but',\n",
              " 'not',\n",
              " 'the',\n",
              " 'will',\n",
              " 'You',\n",
              " 'might',\n",
              " 'also',\n",
              " 'like',\n",
              " 'Amor',\n",
              " 'al',\n",
              " 'Arte',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Tinta',\n",
              " 'y',\n",
              " 'Tiempo',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Asilo',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Pre',\n",
              " 'Estribillo',\n",
              " 'Nora',\n",
              " 'Erez',\n",
              " 'So',\n",
              " 'if',\n",
              " 'you',\n",
              " 'want',\n",
              " 'me',\n",
              " 'to',\n",
              " 'want',\n",
              " 'what',\n",
              " 'I',\n",
              " 'believe',\n",
              " 'that',\n",
              " 'I',\n",
              " 'want',\n",
              " 'Can',\n",
              " 'I',\n",
              " 'choose',\n",
              " 'to',\n",
              " 'quit',\n",
              " 'Estribillo',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Dime',\n",
              " 'qué',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " 'Oh',\n",
              " 'algoritmo',\n",
              " 'Sé',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " 'Verso',\n",
              " '2',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Por',\n",
              " 'ejemplo',\n",
              " 'esta',\n",
              " 'canción',\n",
              " 'Qué',\n",
              " 'algoritmo',\n",
              " 'la',\n",
              " 'parió',\n",
              " 'Me',\n",
              " 'pregunto',\n",
              " 'si',\n",
              " 'fui',\n",
              " 'yo',\n",
              " 'La',\n",
              " 'elegiste',\n",
              " 'o',\n",
              " 'te',\n",
              " 'eligió',\n",
              " 'Verso',\n",
              " '3',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Dios',\n",
              " 'era',\n",
              " 'la',\n",
              " 'letra',\n",
              " 'chica',\n",
              " 'al',\n",
              " 'final',\n",
              " 'del',\n",
              " 'papel',\n",
              " 'Ya',\n",
              " 'no',\n",
              " 'contamos',\n",
              " 'con',\n",
              " 'Él',\n",
              " 'Fin',\n",
              " 'de',\n",
              " 'la',\n",
              " 'Luna',\n",
              " 'de',\n",
              " 'miel',\n",
              " 'Y',\n",
              " 'el',\n",
              " 'libre',\n",
              " 'albedrío',\n",
              " 'es',\n",
              " 'un',\n",
              " 'cauce',\n",
              " 'vacío',\n",
              " 'Un',\n",
              " 'barco',\n",
              " 'que',\n",
              " 'no',\n",
              " 'tiene',\n",
              " 'río',\n",
              " 'Ni',\n",
              " 'timonel',\n",
              " 'Verso',\n",
              " '4',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Todos',\n",
              " 'aplauden',\n",
              " 'tú',\n",
              " 'también',\n",
              " 'Pero',\n",
              " 'no',\n",
              " 'queda',\n",
              " 'claro',\n",
              " 'quién',\n",
              " 'Tiene',\n",
              " 'del',\n",
              " 'mango',\n",
              " 'a',\n",
              " 'la',\n",
              " 'sartén',\n",
              " 'Del',\n",
              " 'sacrificio',\n",
              " 'Piel',\n",
              " 'o',\n",
              " 'silicio',\n",
              " 'Y',\n",
              " 'el',\n",
              " 'precipicio',\n",
              " 'Dice',\n",
              " 'Ven',\n",
              " 'ven',\n",
              " 'ven',\n",
              " 'Refrán',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Dime',\n",
              " 'qué',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Oh',\n",
              " 'algoritmo',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Sé',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Dime',\n",
              " 'qué',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Oh',\n",
              " 'algoritmo',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Sé',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'Wow']"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens = get_tokens(texto)\n",
        "tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CpZKljrotLa"
      },
      "source": [
        "### Pregunta 1.b (0.25 puntos)\n",
        "Explique su implementación aquí:\n",
        "La implementación ... Esta librería \"re\" cuyo método findall(r'\\b\\w+\\b',texto) es tal que; \\b es un límite de palabra (asegura que no tomemos fragmentos de palabras como partes de los tokens), \\w+ captura una o más letras, números o guiones bajos (es decir, palabras). Esto asegura que cada token sea una secuencia de caracteres alfanuméricos. Esta expresión regular no captura signos de puntuación ni espacios, solo las palabras. Por ejemplo, si tenemos \n",
        "\n",
        ">movie_str = \"the evening shows start at 7:00pm and 10:15pm\"\n",
        "\n",
        ">matches = re.findall(r\"([\\d:,.]+)(am|pm)?\", movie_str)\n",
        "\n",
        "devolverá lo siguiente: \n",
        "\n",
        ">[(\"7:00\", \"pm\"), (\"10:15\", \"pm\")]. \n",
        "\n",
        "Entonces la sintaxis general de re.findall es la [siguiente](https://www.codecademy.com/resources/docs/python/regex/findall): re.findall(<pattern>, string), donde pattern vendría siendo el patrón que puede incluir un string, un código de clase de carácter como /w, /s o /d, o bien un símbolo regular como $, | y ^."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIwAKWZvofEp"
      },
      "source": [
        "Implementación con la libreria NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GR2Z0lnnPB9",
        "outputId": "65500454-2fbd-4e49-9e45-71fd08a8f6e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[',\n",
              " 'Letra',\n",
              " 'de',\n",
              " '\"¡',\n",
              " 'Oh',\n",
              " ',',\n",
              " 'Algoritmo',\n",
              " '!\"',\n",
              " 'ft',\n",
              " '.',\n",
              " 'Nora',\n",
              " 'Erez',\n",
              " ']',\n",
              " '[',\n",
              " 'Refrán',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " '¿',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¿',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¿',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¿',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¿',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¿',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '[',\n",
              " 'Estribillo',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " 'Dime',\n",
              " 'qué',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " 'Oh',\n",
              " ',',\n",
              " 'algoritmo',\n",
              " 'Sé',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " '[',\n",
              " 'Verso',\n",
              " '1',\n",
              " ':',\n",
              " 'Nora',\n",
              " 'Erez',\n",
              " ']',\n",
              " 'Wait',\n",
              " ',',\n",
              " 'what',\n",
              " \"'\",\n",
              " 's',\n",
              " 'that',\n",
              " 'money',\n",
              " 'that',\n",
              " 'you',\n",
              " 'spent',\n",
              " '?',\n",
              " 'What',\n",
              " \"'\",\n",
              " 's',\n",
              " 'that',\n",
              " 'sitting',\n",
              " 'on',\n",
              " 'your',\n",
              " 'plate',\n",
              " '?',\n",
              " 'Do',\n",
              " 'you',\n",
              " 'want',\n",
              " 'what',\n",
              " 'you',\n",
              " \"'\",\n",
              " 've',\n",
              " 'been',\n",
              " 'fed',\n",
              " '?',\n",
              " 'Are',\n",
              " 'you',\n",
              " 'the',\n",
              " 'fish',\n",
              " 'or',\n",
              " 'bait',\n",
              " '?',\n",
              " 'Mmm',\n",
              " ',',\n",
              " 'I',\n",
              " \"'\",\n",
              " 'm',\n",
              " 'on',\n",
              " 'the',\n",
              " 'top',\n",
              " 'of',\n",
              " 'the',\n",
              " 'roof',\n",
              " 'and',\n",
              " 'I',\n",
              " 'feel',\n",
              " 'like',\n",
              " 'a',\n",
              " 'jail',\n",
              " 'Rather',\n",
              " 'not',\n",
              " 'pay',\n",
              " 'the',\n",
              " 'bail',\n",
              " 'To',\n",
              " 'dangerous',\n",
              " 'people',\n",
              " 'with',\n",
              " 'blood',\n",
              " 'on',\n",
              " 'their',\n",
              " 'faces',\n",
              " 'So',\n",
              " 'I',\n",
              " \"'\",\n",
              " 'm',\n",
              " 'sharing',\n",
              " 'a',\n",
              " 'cell',\n",
              " 'with',\n",
              " 'the',\n",
              " 'masses',\n",
              " 'The',\n",
              " 'underground',\n",
              " 'always',\n",
              " 'strive',\n",
              " 'for',\n",
              " 'the',\n",
              " 'main',\n",
              " 'Streaming',\n",
              " 'like',\n",
              " 'Grande',\n",
              " \"'\",\n",
              " 's',\n",
              " 'big',\n",
              " '-',\n",
              " 'ass',\n",
              " 'ring',\n",
              " 'Screaming',\n",
              " ':',\n",
              " 'I',\n",
              " \"'\",\n",
              " 'll',\n",
              " 'write',\n",
              " 'you',\n",
              " 'out',\n",
              " 'my',\n",
              " 'will',\n",
              " 'Conscious',\n",
              " 'is',\n",
              " 'free',\n",
              " ',',\n",
              " 'but',\n",
              " 'not',\n",
              " 'the',\n",
              " 'will',\n",
              " 'Conscious',\n",
              " 'is',\n",
              " 'free',\n",
              " ',',\n",
              " 'but',\n",
              " 'not',\n",
              " 'the',\n",
              " 'will',\n",
              " 'You',\n",
              " 'might',\n",
              " 'also',\n",
              " 'like',\n",
              " 'Amor',\n",
              " 'al',\n",
              " 'Arte',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Tinta',\n",
              " 'y',\n",
              " 'Tiempo',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Asilo',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " '[',\n",
              " 'Pre',\n",
              " '-',\n",
              " 'Estribillo',\n",
              " ':',\n",
              " 'Nora',\n",
              " 'Erez',\n",
              " ']',\n",
              " 'So',\n",
              " 'if',\n",
              " 'you',\n",
              " 'want',\n",
              " 'me',\n",
              " 'to',\n",
              " 'want',\n",
              " 'what',\n",
              " 'I',\n",
              " 'believe',\n",
              " 'that',\n",
              " 'I',\n",
              " 'want',\n",
              " 'Can',\n",
              " 'I',\n",
              " 'choose',\n",
              " 'to',\n",
              " 'quit',\n",
              " '?',\n",
              " '[',\n",
              " 'Estribillo',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " 'Dime',\n",
              " 'qué',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " 'Oh',\n",
              " ',',\n",
              " 'algoritmo',\n",
              " 'Sé',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " '[',\n",
              " 'Verso',\n",
              " '2',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " 'Por',\n",
              " 'ejemplo',\n",
              " ',',\n",
              " 'esta',\n",
              " 'canción',\n",
              " '¿',\n",
              " 'Qué',\n",
              " 'algoritmo',\n",
              " 'la',\n",
              " 'parió',\n",
              " '?',\n",
              " 'Me',\n",
              " 'pregunto',\n",
              " 'si',\n",
              " 'fui',\n",
              " 'yo',\n",
              " '¿',\n",
              " 'La',\n",
              " 'elegiste',\n",
              " 'o',\n",
              " 'te',\n",
              " 'eligió',\n",
              " '?',\n",
              " '[',\n",
              " 'Verso',\n",
              " '3',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " 'Dios',\n",
              " 'era',\n",
              " 'la',\n",
              " 'letra',\n",
              " 'chica',\n",
              " 'al',\n",
              " 'final',\n",
              " 'del',\n",
              " 'papel',\n",
              " 'Ya',\n",
              " 'no',\n",
              " 'contamos',\n",
              " 'con',\n",
              " 'Él',\n",
              " 'Fin',\n",
              " 'de',\n",
              " 'la',\n",
              " 'Luna',\n",
              " 'de',\n",
              " 'miel',\n",
              " 'Y',\n",
              " 'el',\n",
              " 'libre',\n",
              " 'albedrío',\n",
              " 'es',\n",
              " 'un',\n",
              " 'cauce',\n",
              " 'vacío',\n",
              " 'Un',\n",
              " 'barco',\n",
              " 'que',\n",
              " 'no',\n",
              " 'tiene',\n",
              " 'río',\n",
              " 'Ni',\n",
              " 'timonel',\n",
              " '[',\n",
              " 'Verso',\n",
              " '4',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " 'Todos',\n",
              " 'aplauden',\n",
              " ',',\n",
              " 'tú',\n",
              " 'también',\n",
              " 'Pero',\n",
              " 'no',\n",
              " 'queda',\n",
              " 'claro',\n",
              " 'quién',\n",
              " 'Tiene',\n",
              " 'del',\n",
              " 'mango',\n",
              " 'a',\n",
              " 'la',\n",
              " 'sartén',\n",
              " 'Del',\n",
              " 'sacrificio',\n",
              " 'Piel',\n",
              " 'o',\n",
              " 'silicio',\n",
              " 'Y',\n",
              " 'el',\n",
              " 'precipicio',\n",
              " 'Dice',\n",
              " ':',\n",
              " 'Ven',\n",
              " ',',\n",
              " 'ven',\n",
              " ',',\n",
              " 'ven',\n",
              " '[',\n",
              " 'Refrán',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " '¿',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¿',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¿',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Dime',\n",
              " 'qué',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " ')',\n",
              " '¿',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¿',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Oh',\n",
              " ',',\n",
              " 'algoritmo',\n",
              " ')',\n",
              " '¿',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Sé',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " ')',\n",
              " '¿',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¿',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " ')',\n",
              " '¿',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Dime',\n",
              " 'qué',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " ')',\n",
              " '¿',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¿',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Oh',\n",
              " ',',\n",
              " 'algoritmo',\n",
              " ')',\n",
              " '¿',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Sé',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " ')',\n",
              " '¿',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¿',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " ')',\n",
              " '¿',\n",
              " 'Quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Wow',\n",
              " ')']"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "nltk_tokens = wordpunct_tokenize(texto)\n",
        "nltk_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so3P4OeGn-qo"
      },
      "source": [
        "### Pregunta 1.c (0.5 puntos)\n",
        "¿Qué diferencias y similitudes encontrase al comparar la función de tokenización creada manualmente por ti contra la implementación de NLTK, al tokenizar la letra de la canción \"Oh, algoritmo\"?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E12BZ29JoFCp"
      },
      "source": [
        ">Una diferencia que encontré es que en el caso de la función de tokenización creada a mano no se aceptan tokens como simbolos tales como \"?\", \")\", \"]\", etc., mientras que en el NLTK sí. Una similitud es que parecen respetar el orden del texto original, es decir, parecen guardar elementos secuencialmente en orden de aparición a medida que van leyendo el teto. Por otro lado, en la función que definí yo es necesario especificar los caracteres que se consideran válidos, mientras que en la NLTK no. Así mismo, la función mía aceptaba letras como â o Â, mientras que la NLTK no, quizás debido a su enfoque. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmUULnB6hWcl"
      },
      "source": [
        "## P2. Stemming y Stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LskhxOLdpT9q"
      },
      "source": [
        "En esta sección debera implementar funciones de stemming y stopwords basado en lo visto en clase. En la siguiente celda tiene el corpus que usara en esta sección:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Recordemos que las **stopwords** son palabras muy comunes en un idioma, como “el”, “de” o “y” en español, que suelen eliminarse en tareas de procesamiento de texto porque no aportan información relevante para el análisis. Por otro lado, el **stemming** es una técnica que reduce las palabras a su raíz o forma base, aunque esta raíz no siempre sea una palabra real, con el objetivo de agrupar variantes como “jugando”, “jugará” o “jugaban” bajo un mismo \"stem\" como “jug”. Ambas técnicas ayudan a simplificar el texto y reducir la dimensionalidad en modelos de lenguaje."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "hj07_CmwhYxk"
      },
      "outputs": [],
      "source": [
        "# Corpus en español\n",
        "corpus_espanol = [\n",
        "    \"¿Quién quiere que yo quiera lo que creo que quiero?\",\n",
        "    \"Dime qué debo cantar\",\n",
        "    \"Sé que lo sabes mejor\"\n",
        "]\n",
        "\n",
        "# Corpus en inglés\n",
        "corpus_ingles = [\n",
        "    \"What's that sitting on your plate?\",\n",
        "    \"Do you want what you've been fed?\",\n",
        "    \"Are you the fish or bait?\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xRyOVbVWwJ5"
      },
      "source": [
        "### Pregunta 2.a (0.5 puntos)\n",
        "Implemente una función **`get_vocab()`** que extraiga los tokens de un corpus. Puede utilizar la función de la sección anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "F-727zL3ptDZ"
      },
      "outputs": [],
      "source": [
        "def get_vocab(corpus):\n",
        "    \"\"\"\n",
        "    Tokenizamos todo el corpus y\n",
        "    luego extraemos solo los tokens alfabéticos.\n",
        "    \"\"\"\n",
        "    s = []\n",
        "    for i in range(len(corpus)):\n",
        "        tokens = wordpunct_tokenize(corpus[i])\n",
        "        s += [t.lower() for t in tokens if t.isalpha()]\n",
        "    return s\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ge2cPS7fqYXy",
        "outputId": "2b5f148c-15cc-461a-c12e-ca9562f2639e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['quién',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " 'dime',\n",
              " 'qué',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " 'sé',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor']"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_espanol = get_vocab(corpus_espanol)\n",
        "vocab_espanol"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCFtzHUbzJqt"
      },
      "source": [
        "Resultado esperado (el orden puede variar):\n",
        "```\n",
        "['yo', 'debo', 'creo', 'Dime', 'lo', 'cantar', 'mejor', 'Sé', 'que', 'quiere', 'quiero', 'sabes', 'Quién', 'quiera', 'qué']\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apRK_d8uqlSm",
        "outputId": "b6460bf1-b8bf-471b-e97f-1789e7367348"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['what',\n",
              " 's',\n",
              " 'that',\n",
              " 'sitting',\n",
              " 'on',\n",
              " 'your',\n",
              " 'plate',\n",
              " 'do',\n",
              " 'you',\n",
              " 'want',\n",
              " 'what',\n",
              " 'you',\n",
              " 've',\n",
              " 'been',\n",
              " 'fed',\n",
              " 'are',\n",
              " 'you',\n",
              " 'the',\n",
              " 'fish',\n",
              " 'or',\n",
              " 'bait']"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_ingles = get_vocab(corpus_ingles)\n",
        "vocab_ingles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvWMUQq5zPP8"
      },
      "source": [
        "Resultado esperado:\n",
        "```\n",
        "['fed', 'been', 'or', 'want', 'plate', 'the', 've', 'your', 's', 'you', 'what', 'Are', 'bait', 'What', 'fish', 'that', 'sitting', 'Do', 'on']\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FVjU3cAzDkw"
      },
      "source": [
        "### Pregunta 2.b (0.5 puntos)\n",
        "Ahora diseñe reglas que usted estime convenientes tanto de **Stemming** como de **Stopwords**. Implemente una función que reciba una lista con los elementos del vocabulario, le aplique sus reglas y devuelva el vocabulario preprocesado. Explique las reglas de stemming y elección de stopwords:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZSeU-rDYbI1"
      },
      "source": [
        "    Explique sus reglas aquí:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aquí las dos reglas funcionan de la siguiente manera. Primero que todo, se usa la [documentación para Stemming](https://spotintelligence.com/2022/12/14/stemming-python/#1_NLTK_stemming) usando la función Stemmer (que en realidad lo que hace es tomar la raíz de cada palabra), mientras que para la regla de stopping words se usa [la librería stopwords](https://pythonspot.com/nltk-stop-words/) que contiene una lista de stopwords en inglés o en español dependiendo del idioma que uno le dé. Además, dicha función la aplicamos como filtro en la misma definición del string que queremos que la función pre_processing nos devuelva. Este filtro es de la siguiente manera: considera todas las palabras cuyas raíces están en la instancia inicializada Stemmer, y a la vez que no están en el conjunto de palabras que están en stop_words. Además, dicha función que implementamos incluye una transformación de las palabras en español para los strings de los idiomas, a inglés, porque la función stopwords recibe strings en inglés. Algo a tener en cuenta es el hecho de que el stemming se aplica a la raíz de las palabras, y en cambio el quitar las stopwords se aplica sobre las palabras completas. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "777xbIG2sqy5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/diegoespinoza/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/diegoespinoza/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "def pre_processing(vocabulario, idioma):\n",
        "    \"\"\"como podemos ver, la función recibe un vocabulario en un idioma\n",
        "    determinado, lo que implica que debemos hacer que la funcion \n",
        "    identifique ese cambio.\"\"\"\n",
        "    if idioma == \"espanol\":\n",
        "        idioma = \"spanish\"\n",
        "    elif idioma == \"ingles\":\n",
        "        idioma = \"english\"\n",
        "    stemmer = PorterStemmer()\n",
        "    \n",
        "    stop_words = set(stopwords.words(idioma))\n",
        "    palabras = get_vocab(vocabulario)\n",
        "\n",
        "    \"\"\"ahora se ve que las palabras que están en \"palabras\" sean tales que \n",
        "    no incluyan números, caracteres especiales o espacios (mediante la condición if palabra.isalpha())\n",
        "    y que dichas palabras además no sean stopwords. Además, stemmer.stem(palabra) es una función que \n",
        "    reduce cada palabra a su raíz en dicho idioma. Aquí en un solo filtro aplicamos primero\n",
        "    stemming y luego quitamos todas las palabras que son stopwords.\"\"\"\n",
        "    palabras_procesadas = [stemmer.stem(palabra) for palabra in palabras if palabra.isalpha() and palabra not in stop_words]\n",
        "    return palabras_procesadas\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT1Rr0das2Nb",
        "outputId": "503fd5f8-ee46-4367-bee1-f85fb24cea03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulario procesado en español: ['quién', 'quier', 'quiera', 'creo', 'quiero', 'dime', 'debo', 'cantar', 'sé', 'sabe', 'mejor'] \n",
            "\n",
            "Vocabulario procesado en inglés: ['sit', 'plate', 'want', 'fed', 'fish', 'bait'] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Aplicar preprocesamiento a los vocabularios de ejemplo con NLTK\n",
        "vocab_procesado_espanol = pre_processing(vocab_espanol, 'espanol')\n",
        "vocab_procesado_ingles = pre_processing(vocab_ingles, 'ingles')\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"Vocabulario procesado en español:\", vocab_procesado_espanol, \"\\n\")\n",
        "print(\"Vocabulario procesado en inglés:\", vocab_procesado_ingles, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ajmn1HaNhZE9"
      },
      "source": [
        "## P3. Bag of Words (0.5 puntos)\n",
        "Considere el siguiente corpus, donde cada elemento del arreglo representa un documento:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "vT0XQM2Ghlvy"
      },
      "outputs": [],
      "source": [
        "d0 = 'El pájaro come semillas'\n",
        "d1 = 'El pájaro se despierta y canta'\n",
        "d2 = 'El pájaro canta y come semillas'\n",
        "d3 = 'El pez come y nada en el agua'\n",
        "d4 = 'El pez empieza a nadar'\n",
        "d5 = 'El pez come alimento'\n",
        "corpus = [d0, d1, d2, d3, d4, d5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeOOz1Su2ATf"
      },
      "source": [
        "El objetivo da las siguientes secciones es determinar cuáles de  los documentos entregados son los más similares entre sí. Para ello utilizaremos la técnica **TF-IDF**.\n",
        "\n",
        "Como los algoritmos de Machine Learning no comprenden el texto en lenguaje natural, estos documentos deben ser convertidos a vectores numéricos. La representación más simple vista en clases es la de **Bag of Words**, método mediante el cual se cuentan las apariciones de cada palabra en cada uno de los documentos entregados.\n",
        "\n",
        "Implemente la función **`bag_of_words()`**, que recibe como input un arreglo de documentos y devuelve un dataframe de pandas con la representación Bag of Words de los documentos entregados. En esta representación las columnas son el vocabulario y las filas representan las apariciones de cada una de las palabras en los documentos. En otras palabras, cada fila representa el BoW de un documento.\n",
        "\n",
        "***Disclaimer: el orden de los resultados pueden variar.***\n",
        "\n",
        "\n",
        "Por ejemplo para el siguiente corpus:\n",
        "\n",
        "```\n",
        "corpus = ['El perro ladra', 'El perro come']\n",
        "```\n",
        "\n",
        "Debiese entregarnos lo siguiente:\n",
        "\n",
        "\n",
        "|   | el | perro | ladra | come |\n",
        "|---|----|-------|------|-------|\n",
        "| 0 | 1  | 1     | 1    | 0     |\n",
        "| 1 | 1  | 1     | 0    | 1     |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "_njmcRPM2GpV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MENCbDO8s_ls"
      },
      "source": [
        "Implementar función `bag_of_words()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación definiremos un diccionario para poder ir guardando las palabras en el orden en el que aparecen, lo cual nos importa principalmente porque preserva dicho orden. El mismo, para una frase como: [\"el perro corre\", \"el gato salta\"] devolverá:\n",
        "```python\n",
        "vocabulario_dict = {\n",
        "    'el': None,\n",
        "    'perro': None,\n",
        "    'corre': None}\n",
        "y si luego hago lo mismo pero con la otra parte del corpus:\n",
        "```python\n",
        "vocabulario_dict = {\n",
        "    'el': None,\n",
        "    'perro': None,\n",
        "    'corre': None,\n",
        "    'gato': None,\n",
        "    'salta': None\n",
        "}\n",
        "por lo tanto podemos decir que la parte del None no nos importa o es irrelevante porque no nos importa la llave sino el valor. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "\n",
        "def obtener_tokens(frase):\n",
        "    \"\"\"\n",
        "    Función auxiliar para tokenizar una frase en español.\n",
        "    \n",
        "    Input:\n",
        "        frase (str): Una oración en español.\n",
        "        \n",
        "    Output:\n",
        "        list: Lista de palabras en minúscula y sin signos de puntuación.\n",
        "    \"\"\"\n",
        "    return [t.lower() for t in wordpunct_tokenize(frase) if t.isalpha()]\n",
        "\n",
        "\n",
        "def bag_of_words(corpus):\n",
        "    \"\"\"\n",
        "    Construye una representación binaria de bolsa de palabras para un corpus de oraciones en español.\n",
        "\n",
        "    1. Extrae todas las palabras únicas (vocabulario) del corpus.\n",
        "       - Se usa un diccionario para preservar el orden de aparición.\n",
        "       \n",
        "    2. Construye un vector binario para cada oración.\n",
        "       - Cada vector tiene 1 si la palabra está presente en la oración, 0 si no.\n",
        "\n",
        "    Input:\n",
        "        corpus (list of str): Lista de oraciones.\n",
        "    \n",
        "    Output:\n",
        "        DataFrame: Matriz binaria con palabras como columnas y oraciones como filas.\n",
        "    \"\"\"\n",
        "    vocabulario_dict = {}\n",
        "    for frase in corpus:\n",
        "        tokens = obtener_tokens(frase)\n",
        "        for token in tokens:\n",
        "            if token not in vocabulario_dict:\n",
        "                vocabulario_dict[token] = None\n",
        "\n",
        "    vocabulario = list(vocabulario_dict.keys())\n",
        "    indice_vocab = {palabra: idx for idx, palabra in enumerate(vocabulario)}\n",
        "\n",
        "    matrix = []\n",
        "    for frase in corpus:\n",
        "        tokens_unicos = set(obtener_tokens(frase))\n",
        "        vector = [0] * len(vocabulario)\n",
        "        for token in tokens_unicos:\n",
        "            if token in indice_vocab:\n",
        "                vector[indice_vocab[token]] = 1\n",
        "        matrix.append(vector)\n",
        "\n",
        "    bag_of_words_df = pd.DataFrame(matrix, columns=vocabulario)\n",
        "    return bag_of_words_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "jWZyXGra2FOw",
        "outputId": "1b5d13ff-96c7-49c9-e400-c12441976874"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>el</th>\n",
              "      <th>pájaro</th>\n",
              "      <th>come</th>\n",
              "      <th>semillas</th>\n",
              "      <th>se</th>\n",
              "      <th>despierta</th>\n",
              "      <th>y</th>\n",
              "      <th>canta</th>\n",
              "      <th>pez</th>\n",
              "      <th>nada</th>\n",
              "      <th>en</th>\n",
              "      <th>agua</th>\n",
              "      <th>empieza</th>\n",
              "      <th>a</th>\n",
              "      <th>nadar</th>\n",
              "      <th>alimento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   el  pájaro  come  semillas  se  despierta  y  canta  pez  nada  en  agua  \\\n",
              "0   1       1     1         1   0          0  0      0    0     0   0     0   \n",
              "1   1       1     0         0   1          1  1      1    0     0   0     0   \n",
              "2   1       1     1         1   0          0  1      1    0     0   0     0   \n",
              "3   1       0     1         0   0          0  1      0    1     1   1     1   \n",
              "4   1       0     0         0   0          0  0      0    1     0   0     0   \n",
              "5   1       0     1         0   0          0  0      0    1     0   0     0   \n",
              "\n",
              "   empieza  a  nadar  alimento  \n",
              "0        0  0      0         0  \n",
              "1        0  0      0         0  \n",
              "2        0  0      0         0  \n",
              "3        0  0      0         0  \n",
              "4        1  1      1         0  \n",
              "5        0  0      0         1  "
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_bow = bag_of_words(corpus)\n",
        "dataset_bow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qEA2Ic2sLlh"
      },
      "source": [
        "Solución esperada:\n",
        "\n",
        "|    |   El |   pájaro |   despierta |   el |   come |   a |   nadar |   se |   en |   y |   alimento |   semillas |   pez |   empieza |   canta |   agua |   nada |\n",
        "|:---|-----:|---------:|------------:|-----:|-------:|----:|--------:|-----:|-----:|----:|-----------:|-----------:|------:|----------:|--------:|-------:|-------:|\n",
        "| d0 |    1 |        1 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   0 |          0 |          1 |     0 |         0 |       0 |      0 |      0 |\n",
        "| d1 |    1 |        1 |           1 |    0 |      0 |   0 |       0 |    1 |    0 |   1 |          0 |          0 |     0 |         0 |       1 |      0 |      0 |\n",
        "| d2 |    1 |        1 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   1 |          0 |          1 |     0 |         0 |       1 |      0 |      0 |\n",
        "| d3 |    1 |        0 |           0 |    1 |      1 |   0 |       0 |    0 |    1 |   1 |          0 |          0 |     1 |         0 |       0 |      1 |      1 |\n",
        "| d4 |    1 |        0 |           0 |    0 |      0 |   1 |       1 |    0 |    0 |   0 |          0 |          0 |     1 |         1 |       0 |      0 |      0 |\n",
        "| d5 |    1 |        0 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   0 |          1 |          0 |     1 |         0 |       0 |      0 |      0 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMv3UZdRhgqT"
      },
      "source": [
        "## P4. TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oxW5CZjhoE9"
      },
      "source": [
        "### 4.a TF (0.25 puntos)\n",
        "\n",
        "Ahora debemos usar el dataframe del ejercicio anterior para calcular la matriz de TF normalizada por la máxima frecuencia $\\max_i({\\text{tf}_{i,j}})$, donde\n",
        "$i$ corresponde al índice de las filas (BoW) y $j$ al de las columnas (palabras). Es decir, dividir cada BoW sobre la cantidad de veces de la palabra que aparezca más veces en ese vector.\n",
        "\n",
        "\n",
        "$$\\text{nft}_{i,j} = \\frac{\\text{tf}_{i,j}}{\\max_i({\\text{tf}_{i,j})}}$$\n",
        "\n",
        "Implemente la función `calc_tf(dataset_bow)`, que entrega la matriz de TF normalizada del BoW del dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "qQhnJuuShmR5"
      },
      "outputs": [],
      "source": [
        "def calc_tf(dataset_bow):\n",
        "    ### Aquí inicia tu código ###\n",
        "    pass\n",
        "    ### Aquí termina tu código ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "urDKFQVu2p3V",
        "outputId": "e26338b6-05e9-423f-afca-9fc621ebccd3"
      },
      "outputs": [],
      "source": [
        "tf = calc_tf(dataset_bow)\n",
        "tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Swo3ZjwVtZlq"
      },
      "source": [
        "Solución esperada:\n",
        "\n",
        "|    |   El |   pájaro |   despierta |   el |   come |   a |   nadar |   se |   en |   y |   alimento |   semillas |   pez |   empieza |   canta |   agua |   nada |\n",
        "|:---|-----:|---------:|------------:|-----:|-------:|----:|--------:|-----:|-----:|----:|-----------:|-----------:|------:|----------:|--------:|-------:|-------:|\n",
        "| d0 |    1 |        1 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   0 |          0 |          1 |     0 |         0 |       0 |      0 |      0 |\n",
        "| d1 |    1 |        1 |           1 |    0 |      0 |   0 |       0 |    1 |    0 |   1 |          0 |          0 |     0 |         0 |       1 |      0 |      0 |\n",
        "| d2 |    1 |        1 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   1 |          0 |          1 |     0 |         0 |       1 |      0 |      0 |\n",
        "| d3 |    1 |        0 |           0 |    1 |      1 |   0 |       0 |    0 |    1 |   1 |          0 |          0 |     1 |         0 |       0 |      1 |      1 |\n",
        "| d4 |    1 |        0 |           0 |    0 |      0 |   1 |       1 |    0 |    0 |   0 |          0 |          0 |     1 |         1 |       0 |      0 |      0 |\n",
        "| d5 |    1 |        0 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   0 |          1 |          0 |     1 |         0 |       0 |      0 |      0 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh2bFyHFhpbM"
      },
      "source": [
        "### 4.b IDF (0.5 puntos)\n",
        "\n",
        "Implementar `calc_idf(dataset_bow)`. Ésta debe retornar un diccionario en donde las llaves sean las palabras y los valores sean el cálculo de cada idf por palabra.\n",
        "\n",
        "Recordar que $\\text{idf}_{t_i} = \\log_{10}\\frac{N}{n_i}$ con $N = $ número de documentos y $n_i = $ número de documentos que contienen la palabra $t_i$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "tGLjlSY02usu"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "qoU4AIrm2sDT"
      },
      "outputs": [],
      "source": [
        "def calc_idf(dataset_bow):\n",
        "    ### Aquí inicia tu código ###\n",
        "    pass\n",
        "    ### Aquí termina tu código ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXPErPdw2uQx",
        "outputId": "6f4076e5-79e5-4d21-d233-913c3a47adab"
      },
      "outputs": [],
      "source": [
        "idf = calc_idf(dataset_bow)\n",
        "idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmp5lXdquAD1"
      },
      "source": [
        "Solución esperada:\n",
        "```\n",
        "{'El': 0.0,\n",
        " 'pájaro': 0.3010299956639812,\n",
        " 'despierta': 0.7781512503836436,\n",
        " 'el': 0.7781512503836436,\n",
        " 'come': 0.17609125905568124,\n",
        " 'a': 0.7781512503836436,\n",
        " 'nadar': 0.7781512503836436,\n",
        " 'se': 0.7781512503836436,\n",
        " 'en': 0.7781512503836436,\n",
        " 'y': 0.3010299956639812,\n",
        " 'alimento': 0.7781512503836436,\n",
        " 'semillas': 0.47712125471966244,\n",
        " 'pez': 0.3010299956639812,\n",
        " 'empieza': 0.7781512503836436,\n",
        " 'canta': 0.47712125471966244,\n",
        " 'agua': 0.7781512503836436,\n",
        " 'nada': 0.7781512503836436}\n",
        " ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC-_vwiV20XL"
      },
      "source": [
        "### 4.c TF-IDF (0.25 puntos)\n",
        "Programe la función `calc_tf_idf(tf, idf)` que entrega el dataframe TF-IDF asociado al dataset que estamos analizando."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "004IuUyt23_6"
      },
      "outputs": [],
      "source": [
        "def calc_tf_idf(tf, idf):\n",
        "    ### Aquí inicia tu código ###\n",
        "    pass\n",
        "    ### Aquí termina tu código ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "KXjP0S3626dw",
        "outputId": "34863c23-c513-4556-d500-5a8e0141d8f8"
      },
      "outputs": [],
      "source": [
        "tf_idf = calc_tf_idf(tf, idf)\n",
        "tf_idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNTa32IsuLWl"
      },
      "source": [
        "Solución esperada:\n",
        "\n",
        "|    |   El |   pájaro |   despierta |       el |     come |        a |    nadar |       se |       en |       y |   alimento |   semillas |     pez |   empieza |    canta |     agua |     nada |\n",
        "|:---|-----:|---------:|------------:|---------:|---------:|---------:|---------:|---------:|---------:|--------:|-----------:|-----------:|--------:|----------:|---------:|---------:|---------:|\n",
        "| d0 |    0 |  0.30103 |    0        | 0        | 0.176091 | 0        | 0        | 0        | 0        | 0       |   0        |   0.477121 | 0       |  0        | 0        | 0        | 0        |\n",
        "| d1 |    0 |  0.30103 |    0.778151 | 0        | 0        | 0        | 0        | 0.778151 | 0        | 0.30103 |   0        |   0        | 0       |  0        | 0.477121 | 0        | 0        |\n",
        "| d2 |    0 |  0.30103 |    0        | 0        | 0.176091 | 0        | 0        | 0        | 0        | 0.30103 |   0        |   0.477121 | 0       |  0        | 0.477121 | 0        | 0        |\n",
        "| d3 |    0 |  0       |    0        | 0.778151 | 0.176091 | 0        | 0        | 0        | 0.778151 | 0.30103 |   0        |   0        | 0.30103 |  0        | 0        | 0.778151 | 0.778151 |\n",
        "| d4 |    0 |  0       |    0        | 0        | 0        | 0.778151 | 0.778151 | 0        | 0        | 0       |   0        |   0        | 0.30103 |  0.778151 | 0        | 0        | 0        |\n",
        "| d5 |    0 |  0       |    0        | 0        | 0.176091 | 0        | 0        | 0        | 0        | 0       |   0.778151 |   0        | 0.30103 |  0        | 0        | 0        | 0        |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8sQEjVshjQ7"
      },
      "source": [
        "## P5. Cosine-similarity (0.25 puntos)\n",
        "Ahora que tenemos el dataframe de TF-IDF, nos queda calcular la similitud coseno entre todos los vectores. Notar que la matriz resultante será una matriz simétrica.\n",
        "\n",
        "Implemente la función *cosine_similarity(v1, v2)* que recibe dos vectores (v1 y v2) y calcula la similitud coseno entre ambos. Concluya cuáles son los dos documentos más similares."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "_68mo-BLhmuV"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(v1, v2):\n",
        "    ### Aquí inicia tu código ###\n",
        "    pass\n",
        "    ### Aquí termina tu código ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5z-23CN2_lU",
        "outputId": "6798f54e-69dc-40c6-ca35-d2d4995fe168"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'index'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[54], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m similarity_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, v1 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtf_idf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[1;32m      3\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m j, v2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tf_idf\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[1;32m      4\u001b[0m       similarity \u001b[38;5;241m=\u001b[39m cosine_similarity(tf_idf\u001b[38;5;241m.\u001b[39mloc[v1]\u001b[38;5;241m.\u001b[39mvalues, tf_idf\u001b[38;5;241m.\u001b[39mloc[v2]\u001b[38;5;241m.\u001b[39mvalues)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'index'"
          ]
        }
      ],
      "source": [
        "similarity_matrix = np.zeros((6,6))\n",
        "for i, v1 in enumerate(tf_idf.index.values):\n",
        "  for j, v2 in enumerate(tf_idf.index.values):\n",
        "      similarity = cosine_similarity(tf_idf.loc[v1].values, tf_idf.loc[v2].values)\n",
        "      similarity_matrix[i][j] = similarity\n",
        "\n",
        "for i in range(6):\n",
        "  mask = [k != i for k in range(6)]\n",
        "  j = np.argmax(similarity_matrix[i][mask])\n",
        "\n",
        "  print(corpus[i])\n",
        "  print(\"> Mas similar:\", np.array(corpus)[mask][j])\n",
        "  print(\"> Similitud:\", similarity_matrix[i][mask][j], \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71oH4JHXulGQ"
      },
      "source": [
        "Solución esperada:\n",
        "```\n",
        "El pájaro come semillas\n",
        "> Mas similar: El pájaro canta y come semillas\n",
        "> Similitud: 0.7233435041520414\n",
        "\n",
        "El pájaro se despierta y canta\n",
        "> Mas similar: El pájaro canta y come semillas\n",
        "> Similitud: 0.39320101823128945\n",
        "\n",
        "El pájaro canta y come semillas\n",
        "> Mas similar: El pájaro come semillas\n",
        "> Similitud: 0.7233435041520414\n",
        "\n",
        "El pez come y nada en el agua\n",
        "> Mas similar: El pájaro canta y come semillas\n",
        "> Similitud: 0.09171890791406168\n",
        "\n",
        "El pez empieza a nadar\n",
        "> Mas similar: El pez come alimento\n",
        "> Similitud: 0.07695078406752713\n",
        "\n",
        "El pez come alimento\n",
        "> Mas similar: El pez come y nada en el agua\n",
        "> Similitud: 0.0878790037217323\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDZln45jfjMf"
      },
      "source": [
        "## P6 N-gramas (0.75 punto)\n",
        "\n",
        "En esta sección debera determinar los n-gramas del la cancion \"Oh algoritmo\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7duKoBvlSgg"
      },
      "source": [
        "### 6.a Corpus de entrenamiento y test (0.25 puntos)\n",
        "\n",
        "En esta subsección debera definir el conjunto de entrenamiento y test de un corpus. Eliga una particion del 80% y 20% del texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juDVurFfl3eZ",
        "outputId": "4c6398a1-ed7b-45ed-cdf7-c5fcd6ffb4c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Letra de \"¡Oh, Algoritmo!\" ft. Nora Erez]\n",
            "\n",
            "[Refrán: Jorge Drexler]\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "\n",
            "[Estribillo: Jorge Drexler]\n",
            "Dime qué debo cantar\n",
            "Oh, algoritmo\n",
            "Sé que lo sabes mejor\n",
            "Incluso que yo mismo\n",
            "\n",
            "[Verso 1: Nora Erez]\n",
            "Wait, what's that money that you spent?\n",
            "What's that sitting on your plate?\n",
            "Do you want what you've been fed?\n",
            "Are you the fish or bait?\n",
            "Mmm, I'm on the top of the roof and I feel like a jail\n",
            "Rather not pay the bail\n",
            "To dangerous people with blood on their faces\n",
            "So I'm sharing a cell with the masses\n",
            "The underground always strive for the main\n",
            "Streaming like Grande's big-ass ring\n",
            "Screaming: I'll write you out my will\n",
            "Conscious is free, but not the will\n",
            "Conscious is free, but not the will\n",
            "You might also like\n",
            "Amor al Arte\n",
            "Jorge Drexler\n",
            "Tinta y Tiempo\n",
            "Jorge Drexler\n",
            "Asilo\n",
            "Jorge Drexler\n",
            "[Pre-Estribillo: Nora Erez]\n",
            "So if you want me to want what I believe that I want\n",
            "Can I choose to quit?\n",
            "\n",
            "[Estribillo: Jorge Drexler]\n",
            "Dime qué debo cantar\n",
            "Oh, algoritmo\n",
            "Sé que lo sabes mejor\n",
            "Incluso que yo mismo\n",
            "\n",
            "[Verso 2: Jorge Drexler]\n",
            "Por ejemplo, esta canción\n",
            "¿Qué algoritmo la parió?\n",
            "Me pregunto si fui yo\n",
            "¿La elegiste o te eligió?\n",
            "\n",
            "[Verso 3: Jorge Drexler]\n",
            "Dios era la letra chica al final del papel\n",
            "Ya no contamos con Él\n",
            "Fin de la Luna de miel\n",
            "Y el libre albedrío es un cauce vacío\n",
            "Un barco que no tiene río\n",
            "Ni timonel\n",
            "\n",
            "[Verso 4: Jorge Drexler]\n",
            "Todos aplauden, tú también\n",
            "Pero no queda claro quién\n",
            "Tiene del mango a la sartén\n",
            "Del sacrificio\n",
            "Piel o silicio\n",
            "Y el precipicio\n",
            "Dice: Ven, ven, ven\n",
            "[Refrán: Jorge Drexler]\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "(Dime qué debo cantar)\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "(Oh, algoritmo)\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "(Sé que lo sabes mejor)\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "(Incluso que yo mismo)\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "(Dime qué debo cantar)\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "(Oh, algoritmo)\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "(Sé que lo sabes mejor)\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "(Incluso que yo mismo)\n",
            "¿Quién quiere que yo quiera lo que creo que quiero?\n",
            "(Wow)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # Abre el archivo en modo lectura (\"r\")\n",
        "    with open(\"oh_algoritmo.txt\", \"r\") as archivo:\n",
        "        # Lee el contenido del archivo\n",
        "        texto = archivo.read()\n",
        "        # Imprime el contenido\n",
        "        print(texto)\n",
        "except FileNotFoundError:\n",
        "    print(\"El archivo no se encuentra.\")\n",
        "except Exception as e:\n",
        "    print(\"Ocurrió un error:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYCw0AqOmlzD"
      },
      "source": [
        "Defina una funcion `get_sentences()` que entregue todas las oraciones del corpus que contengan al menos una palabra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C88f9aVil9d_"
      },
      "outputs": [],
      "source": [
        "def get_sentences(texto):\n",
        "  ## Implementar aquí\n",
        "  pass\n",
        "  ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbZ8EhgHmR2c",
        "outputId": "c4b6502e-889a-4339-ee58-1b427867c405"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[Letra de \"¡Oh, Algoritmo!\" ft. Nora Erez]',\n",
              " '[Refrán: Jorge Drexler]',\n",
              " '¿Quién quiere que yo quiera lo que creo que quiero?',\n",
              " '¿Quién quiere que yo quiera lo que creo que quiero?',\n",
              " '¿Quién quiere que yo quiera lo que creo que quiero?',\n",
              " '¿Quién quiere que yo quiera lo que creo que quiero?',\n",
              " '¿Quién quiere que yo quiera lo que creo que quiero?',\n",
              " '¿Quién quiere que yo quiera lo que creo que quiero?',\n",
              " '[Estribillo: Jorge Drexler]',\n",
              " 'Dime qué debo cantar',\n",
              " 'Oh, algoritmo',\n",
              " 'Sé que lo sabes mejor',\n",
              " 'Incluso que yo mismo',\n",
              " '[Verso 1: Nora Erez]',\n",
              " \"Wait, what's that money that you spent?\",\n",
              " \"What's that sitting on your plate?\",\n",
              " \"Do you want what you've been fed?\",\n",
              " 'Are you the fish or bait?',\n",
              " \"Mmm, I'm on the top of the roof and I feel like a jail\",\n",
              " 'Rather not pay the bail',\n",
              " 'To dangerous people with blood on their faces',\n",
              " \"So I'm sharing a cell with the masses\",\n",
              " 'The underground always strive for the main',\n",
              " \"Streaming like Grande's big-ass ring\",\n",
              " \"Screaming: I'll write you out my will\",\n",
              " 'Conscious is free, but not the will',\n",
              " 'Conscious is free, but not the will',\n",
              " 'You might also like',\n",
              " 'Amor al Arte',\n",
              " 'Jorge Drexler',\n",
              " 'Tinta y Tiempo',\n",
              " 'Jorge Drexler',\n",
              " 'Asilo',\n",
              " 'Jorge Drexler',\n",
              " '[Pre-Estribillo: Nora Erez]',\n",
              " 'So if you want me to want what I believe that I want',\n",
              " 'Can I choose to quit?',\n",
              " '[Estribillo: Jorge Drexler]',\n",
              " 'Dime qué debo cantar',\n",
              " 'Oh, algoritmo',\n",
              " 'Sé que lo sabes mejor',\n",
              " 'Incluso que yo mismo',\n",
              " '[Verso 2: Jorge Drexler]',\n",
              " 'Por ejemplo, esta canción',\n",
              " '¿Qué algoritmo la parió?',\n",
              " 'Me pregunto si fui yo',\n",
              " '¿La elegiste o te eligió?',\n",
              " '[Verso 3: Jorge Drexler]',\n",
              " 'Dios era la letra chica al final del papel',\n",
              " 'Ya no contamos con Él',\n",
              " 'Fin de la Luna de miel',\n",
              " 'Y el libre albedrío es un cauce vacío',\n",
              " 'Un barco que no tiene río',\n",
              " 'Ni timonel',\n",
              " '[Verso 4: Jorge Drexler]',\n",
              " 'Todos aplauden, tú también',\n",
              " 'Pero no queda claro quién',\n",
              " 'Tiene del mango a la sartén',\n",
              " 'Del sacrificio',\n",
              " 'Piel o silicio',\n",
              " 'Y el precipicio',\n",
              " 'Dice: Ven, ven, ven',\n",
              " '[Refrán: Jorge Drexler]',\n",
              " '¿Quién quiere que yo quiera lo que creo que quiero?',\n",
              " '¿Quién quiere que yo quiera lo que creo que quiero?',\n",
              " '¿Quién quiere que yo quiera lo que creo que quiero?',\n",
              " '(Dime qué debo cantar)',\n",
              " '¿Quién quiere que yo quiera lo que creo que quiero?',\n",
              " '¿Quién quiere que yo quiera lo que creo que quiero?',\n",
              " '(Oh, algoritmo)',\n",
              " '¿Quién quiere que yo quiera lo que creo que quiero?',\n",
              " '(Sé que lo sabes mejor)',\n",
              " '¿Quién quiere que yo quiera lo que creo que quiero?',\n",
              " '¿Quién quiere que yo quiera lo que creo que quiero?',\n",
              " '(Incluso que yo mismo)',\n",
              " '¿Quién quiere que yo quiera lo que creo que quiero?',\n",
              " '(Dime qué debo cantar)',\n",
              " '¿Quién quiere que yo quiera lo que creo que quiero?',\n",
              " '¿Quién quiere que yo quiera lo que creo que quiero?',\n",
              " '(Oh, algoritmo)',\n",
              " '¿Quién quiere que yo quiera lo que creo que quiero?',\n",
              " '(Sé que lo sabes mejor)',\n",
              " '¿Quién quiere que yo quiera lo que creo que quiero?',\n",
              " '¿Quién quiere que yo quiera lo que creo que quiero?',\n",
              " '(Incluso que yo mismo)',\n",
              " '¿Quién quiere que yo quiera lo que creo que quiero?',\n",
              " '(Wow)']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "oraciones_limpias = get_sentences(texto)\n",
        "oraciones_limpias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEBzcR6Ym0Us"
      },
      "source": [
        "Debería obtener en total 87 oraciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pDN1vGEmwRQ",
        "outputId": "bdecd9e4-4d9e-4297-9319-8f938fc726ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "87"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(oraciones_limpias) == 87"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp9dq8omm7cD"
      },
      "source": [
        "Ahora definiremos el conjunto de entrenamiento y prueba para las oraciones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVHoR_-inEK1",
        "outputId": "c28b779e-ab7e-4c55-b061-86701fadacba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(69, 18)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split = int(len(oraciones_limpias) * 0.8)\n",
        "train_corpus = oraciones_limpias[:split]\n",
        "test_corpus = oraciones_limpias[split:]\n",
        "\n",
        "len(train_corpus), len(test_corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csdw0qNsmjTF"
      },
      "source": [
        "### 6.b Estimación de N-gramas (0.5 puntos)\n",
        "\n",
        "Defina una función que reciba una lista de oraciones de un corpus y un N que indique el tamaño de los N-gramas. La función debe retornar un diccionario de Python donde la llave es un token (o palabra) y el valor es la cantidad de veces que ocurre el token, es decir, la frecuencia. En el caso de N-gramas con N mayor a 1 (como bi-gramas o tri-gramas) debe añadir un token especial al inicio o final de cada oración según corresponda (ver clases del curso)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bB2_1y1etIBF"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lbrl3WVnmRzj"
      },
      "outputs": [],
      "source": [
        "def n_grams(corpus, n=3):\n",
        "  ## Implementar aquí\n",
        "  pass\n",
        "  ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAoYncsp3C7u"
      },
      "outputs": [],
      "source": [
        "n_grams(train_corpus, n=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8XDEuRF3Grx"
      },
      "outputs": [],
      "source": [
        "n_grams(train_corpus, n=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCpbhiXp3Gpg"
      },
      "outputs": [],
      "source": [
        "n_grams(train_corpus, n=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHgEpVPj21fs"
      },
      "source": [
        "Debe mostrar que su método funciona para $N = 1,2,3$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMzLfBLBk-i7"
      },
      "source": [
        "## P7. Perplexity (1 punto)\n",
        "\n",
        "En esta sección evaluarán su modelo de n-gramas y determinarán la probabilidad de oraciones y la perplejidad con un conjunto de test. Recuerde que la perplejidad se define de la siguiente manera:\n",
        "\n",
        "$$\n",
        "\\text{Perplexity} = 2^{-l} \\quad \\quad l = \\frac{1}{M} \\sum_{i=1}^{m} \\log p(s_i)\n",
        "$$\n",
        "\n",
        "con $m$ el número de oraciones del corpus y $M$ el tamaño del vocabulario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tas4KYhZ28_C"
      },
      "source": [
        "### 7.a Obtener probabilidades (0.5 puntos)\n",
        "\n",
        "En esta sección implementará una función que determine la probabilidad de una oración."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYH0ScM44Jrb"
      },
      "source": [
        "Defina una función que reciba una oración, un diccionario con n-gramas y el valor de $n$. La función debe entregar la probabilidad de cualquier oración.\n",
        "\n",
        "**Hint**: No olvide los posibles casos borde, como palabras fuera del vocabulario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWGsq22H4Sxz"
      },
      "outputs": [],
      "source": [
        "def get_probability(sentence, n_grams_frequency, n):\n",
        "  ## Implementar aquí\n",
        "  pass\n",
        "  ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1UkfOz75W_P"
      },
      "source": [
        "Pruebe su función con oraciones frecuentes y comente sus resultados\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ITfzYJx5fqV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfnIFV7F3eOL"
      },
      "source": [
        "### 7.b Perplexity en conjunto de test (0.5 puntos)\n",
        "\n",
        "En esta sub-sección deberá calcular la perplejidad del corpus de test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N21I_mPl5Cqx"
      },
      "source": [
        "Defina una función que reciba un corpus de test y retorne la perplexity (ver clases del curso). Utilice la función de la sección anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VC4Vbk3q5LsY"
      },
      "outputs": [],
      "source": [
        "def get_perplexity(corpus, n):\n",
        "  ## implementar aquí\n",
        "  pass\n",
        "  ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAjpRDoG5sUJ"
      },
      "outputs": [],
      "source": [
        "get_perplexity(test_corpus, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhc07wXM5gyI"
      },
      "source": [
        "Dé una interpretacion de la perplexity en el corpus de test:\n",
        "```\n",
        "Nosotros ...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYNsmR4OPQQX"
      },
      "source": [
        "## P8. Interpolación Lineal (0.5 puntos)\n",
        "\n",
        "Cree una función que obtenga la probabilidad de una oración interpolando linealmente modelos de unigrama, bigrama y trigrama ponderados por $\\lambda_1, \\lambda_2$ y $\\lambda_3$ respectivamente. Para esto use las funciones que creó anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7kcWusAPPv5"
      },
      "outputs": [],
      "source": [
        "def get_probability_lineal_interpol(sentence, corpus, l_1, l_2, l_3):\n",
        "  ## Implementar aquí\n",
        "  pass\n",
        "  ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO1J_E77RQp3"
      },
      "source": [
        "Defina una función para calcular la perplejidad de un corpus con interpolación lineal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAS94E1UROkg"
      },
      "outputs": [],
      "source": [
        "def get_pp_interpol(corpus, l_1, l_2, l_3):\n",
        "  ## Implementar aquí\n",
        "  pass\n",
        "  ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqoX9_o2SHOY"
      },
      "source": [
        "Ahora haga pruebas con distintos valores de $\\lambda_1, \\lambda_2$ y $\\lambda_3$, incluyendo valores extremos (por ejemplo $[1, 0, 0]$). Comente sus resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZ6-NA3AOUmq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
